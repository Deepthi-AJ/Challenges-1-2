{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f70d846",
   "metadata": {
    "papermill": {
     "duration": 0.004007,
     "end_time": "2023-08-04T11:36:26.376087",
     "exception": false,
     "start_time": "2023-08-04T11:36:26.372080",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ICR - Identifying Age-Related Conditions\n",
    "\n",
    " The goal of the competition is to 'Use Machine Learning to detect conditions with measurements of anonymous characteristics' to help researchers discover the relationship between measurements of certain characteristics and potential patient conditions. Predictive models can be developed to shorten the process of determining if someone has any one of the three medical conditions given in the competition dataset by the traditional long and intrusive process of collecting information from the patients. The model should be capable of predicting the Class 1 which analyses if the person has one or more of any one of the three medical conditions in the log-loss based binary classification involved. The Class 0 would be the prediction of patients who were diagnosed with none of the three medical conditions.\n",
    "\n",
    " The evaluation method for the submissions to be made is carried out using balanced logarithmic loss. Each Class 1 or Class 0 observation based on probability impacts the final score in a equally important manner roughly.\n",
    "    \n",
    "    The overall effect is such that each class is roughly equally important for the final score.\n",
    "\n",
    "Each observation is either of class 0 or of class 1. For each observation, one must submit a probability for each class.\n",
    "\n",
    "The submitted probabilities for a given row are not required to sum to one because they are rescaled prior to being scored (each row is divided by the row sum). In order to avoid the extremes of the log function, each predicted probability \n",
    " is replaced with \n",
    ".\n",
    "\n",
    "Submission File\n",
    "For each id in the test set, you must predict a probability for each of the two classes. The file should contain a header and have the following format:</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b9e7324",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-04T11:36:26.384960Z",
     "iopub.status.busy": "2023-08-04T11:36:26.384558Z",
     "iopub.status.idle": "2023-08-04T11:36:26.393849Z",
     "shell.execute_reply": "2023-08-04T11:36:26.393015Z"
    },
    "papermill": {
     "duration": 0.016367,
     "end_time": "2023-08-04T11:36:26.396138",
     "exception": false,
     "start_time": "2023-08-04T11:36:26.379771",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70695447",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-04T11:36:26.405266Z",
     "iopub.status.busy": "2023-08-04T11:36:26.404272Z",
     "iopub.status.idle": "2023-08-04T11:36:26.457759Z",
     "shell.execute_reply": "2023-08-04T11:36:26.456935Z"
    },
    "papermill": {
     "duration": 0.060432,
     "end_time": "2023-08-04T11:36:26.460177",
     "exception": false,
     "start_time": "2023-08-04T11:36:26.399745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <td>000ff2bfdfe9</td>\n",
       "      <td>007255e47698</td>\n",
       "      <td>013f2bd269f5</td>\n",
       "      <td>043ac50845d5</td>\n",
       "      <td>044fb8a146ec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AB</th>\n",
       "      <td>0.209377</td>\n",
       "      <td>0.145282</td>\n",
       "      <td>0.47003</td>\n",
       "      <td>0.252107</td>\n",
       "      <td>0.380297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AF</th>\n",
       "      <td>3109.03329</td>\n",
       "      <td>978.76416</td>\n",
       "      <td>2635.10654</td>\n",
       "      <td>3819.65177</td>\n",
       "      <td>3733.04844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AH</th>\n",
       "      <td>85.200147</td>\n",
       "      <td>85.200147</td>\n",
       "      <td>85.200147</td>\n",
       "      <td>120.201618</td>\n",
       "      <td>85.200147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AM</th>\n",
       "      <td>22.394407</td>\n",
       "      <td>36.968889</td>\n",
       "      <td>32.360553</td>\n",
       "      <td>77.112203</td>\n",
       "      <td>14.103738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>8.138688</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>8.138688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AX</th>\n",
       "      <td>0.699861</td>\n",
       "      <td>3.63219</td>\n",
       "      <td>6.73284</td>\n",
       "      <td>3.685344</td>\n",
       "      <td>3.942255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AY</th>\n",
       "      <td>0.025578</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>0.05481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>9.812214</td>\n",
       "      <td>13.51779</td>\n",
       "      <td>12.82457</td>\n",
       "      <td>11.053708</td>\n",
       "      <td>3.396778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BC</th>\n",
       "      <td>5.555634</td>\n",
       "      <td>1.2299</td>\n",
       "      <td>1.2299</td>\n",
       "      <td>1.2299</td>\n",
       "      <td>102.15198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BD</th>\n",
       "      <td>4126.58731</td>\n",
       "      <td>5496.92824</td>\n",
       "      <td>5135.78024</td>\n",
       "      <td>4169.67738</td>\n",
       "      <td>5728.73412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BN</th>\n",
       "      <td>22.5984</td>\n",
       "      <td>19.4205</td>\n",
       "      <td>26.4825</td>\n",
       "      <td>23.6577</td>\n",
       "      <td>24.0108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BP</th>\n",
       "      <td>175.638726</td>\n",
       "      <td>155.86803</td>\n",
       "      <td>128.988531</td>\n",
       "      <td>237.282264</td>\n",
       "      <td>324.546318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BQ</th>\n",
       "      <td>152.707705</td>\n",
       "      <td>14.75472</td>\n",
       "      <td>219.32016</td>\n",
       "      <td>11.05041</td>\n",
       "      <td>149.717165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BR</th>\n",
       "      <td>823.928241</td>\n",
       "      <td>51.216883</td>\n",
       "      <td>482.141594</td>\n",
       "      <td>661.51864</td>\n",
       "      <td>6074.859475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BZ</th>\n",
       "      <td>257.432377</td>\n",
       "      <td>257.432377</td>\n",
       "      <td>257.432377</td>\n",
       "      <td>257.432377</td>\n",
       "      <td>257.432377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB</th>\n",
       "      <td>47.223358</td>\n",
       "      <td>30.284345</td>\n",
       "      <td>32.563713</td>\n",
       "      <td>15.201914</td>\n",
       "      <td>82.213495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CC</th>\n",
       "      <td>0.563481</td>\n",
       "      <td>0.48471</td>\n",
       "      <td>0.495852</td>\n",
       "      <td>0.717882</td>\n",
       "      <td>0.536467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CD</th>\n",
       "      <td>23.3876</td>\n",
       "      <td>50.628208</td>\n",
       "      <td>85.955376</td>\n",
       "      <td>88.15936</td>\n",
       "      <td>72.644264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CF</th>\n",
       "      <td>4.851915</td>\n",
       "      <td>6.085041</td>\n",
       "      <td>5.376488</td>\n",
       "      <td>2.347652</td>\n",
       "      <td>30.537722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CH</th>\n",
       "      <td>0.023482</td>\n",
       "      <td>0.031442</td>\n",
       "      <td>0.036218</td>\n",
       "      <td>0.029054</td>\n",
       "      <td>0.025472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CL</th>\n",
       "      <td>1.050225</td>\n",
       "      <td>1.113875</td>\n",
       "      <td>1.050225</td>\n",
       "      <td>1.4003</td>\n",
       "      <td>1.050225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CR</th>\n",
       "      <td>0.069225</td>\n",
       "      <td>1.1178</td>\n",
       "      <td>0.70035</td>\n",
       "      <td>0.636075</td>\n",
       "      <td>0.69315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CS</th>\n",
       "      <td>13.784111</td>\n",
       "      <td>28.310953</td>\n",
       "      <td>39.364743</td>\n",
       "      <td>41.11696</td>\n",
       "      <td>31.724726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CU</th>\n",
       "      <td>1.302012</td>\n",
       "      <td>1.357182</td>\n",
       "      <td>1.009611</td>\n",
       "      <td>0.722727</td>\n",
       "      <td>0.82755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CW</th>\n",
       "      <td>36.205956</td>\n",
       "      <td>37.476568</td>\n",
       "      <td>21.459644</td>\n",
       "      <td>21.530392</td>\n",
       "      <td>34.41536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DA</th>\n",
       "      <td>69.0834</td>\n",
       "      <td>70.79836</td>\n",
       "      <td>70.8197</td>\n",
       "      <td>47.27586</td>\n",
       "      <td>74.06532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DE</th>\n",
       "      <td>295.570575</td>\n",
       "      <td>178.5531</td>\n",
       "      <td>321.426625</td>\n",
       "      <td>196.607985</td>\n",
       "      <td>200.17816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF</th>\n",
       "      <td>0.23868</td>\n",
       "      <td>0.23868</td>\n",
       "      <td>0.23868</td>\n",
       "      <td>0.23868</td>\n",
       "      <td>0.23868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DH</th>\n",
       "      <td>0.284232</td>\n",
       "      <td>0.363489</td>\n",
       "      <td>0.210441</td>\n",
       "      <td>0.292431</td>\n",
       "      <td>0.207708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DI</th>\n",
       "      <td>89.24556</td>\n",
       "      <td>110.581815</td>\n",
       "      <td>120.056438</td>\n",
       "      <td>139.82457</td>\n",
       "      <td>97.92012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DL</th>\n",
       "      <td>84.31664</td>\n",
       "      <td>75.74548</td>\n",
       "      <td>65.46984</td>\n",
       "      <td>71.5712</td>\n",
       "      <td>52.83888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DN</th>\n",
       "      <td>29.657104</td>\n",
       "      <td>37.532</td>\n",
       "      <td>28.053464</td>\n",
       "      <td>24.354856</td>\n",
       "      <td>26.019912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DU</th>\n",
       "      <td>5.31069</td>\n",
       "      <td>0.005518</td>\n",
       "      <td>1.289739</td>\n",
       "      <td>2.655345</td>\n",
       "      <td>1.144902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DV</th>\n",
       "      <td>1.74307</td>\n",
       "      <td>1.74307</td>\n",
       "      <td>1.74307</td>\n",
       "      <td>1.74307</td>\n",
       "      <td>1.74307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DY</th>\n",
       "      <td>23.187704</td>\n",
       "      <td>17.222328</td>\n",
       "      <td>36.861352</td>\n",
       "      <td>52.003884</td>\n",
       "      <td>9.064856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EB</th>\n",
       "      <td>7.294176</td>\n",
       "      <td>4.926396</td>\n",
       "      <td>7.813674</td>\n",
       "      <td>7.38606</td>\n",
       "      <td>7.35072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EE</th>\n",
       "      <td>1.987283</td>\n",
       "      <td>0.858603</td>\n",
       "      <td>8.146651</td>\n",
       "      <td>3.813326</td>\n",
       "      <td>3.490846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EG</th>\n",
       "      <td>1433.16675</td>\n",
       "      <td>1111.28715</td>\n",
       "      <td>1494.076488</td>\n",
       "      <td>15691.55218</td>\n",
       "      <td>1403.6563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EH</th>\n",
       "      <td>0.949104</td>\n",
       "      <td>0.003042</td>\n",
       "      <td>0.377208</td>\n",
       "      <td>0.614484</td>\n",
       "      <td>0.164268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EJ</th>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EL</th>\n",
       "      <td>30.87942</td>\n",
       "      <td>109.125159</td>\n",
       "      <td>109.125159</td>\n",
       "      <td>31.674357</td>\n",
       "      <td>109.125159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EP</th>\n",
       "      <td>78.526968</td>\n",
       "      <td>95.415086</td>\n",
       "      <td>78.526968</td>\n",
       "      <td>78.526968</td>\n",
       "      <td>91.994825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EU</th>\n",
       "      <td>3.828384</td>\n",
       "      <td>52.26048</td>\n",
       "      <td>5.390628</td>\n",
       "      <td>31.323372</td>\n",
       "      <td>51.141336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FC</th>\n",
       "      <td>13.39464</td>\n",
       "      <td>17.175984</td>\n",
       "      <td>224.207424</td>\n",
       "      <td>59.301984</td>\n",
       "      <td>29.10264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FD</th>\n",
       "      <td>10.265073</td>\n",
       "      <td>0.29685</td>\n",
       "      <td>8.745201</td>\n",
       "      <td>7.884336</td>\n",
       "      <td>4.27464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FE</th>\n",
       "      <td>9028.291921</td>\n",
       "      <td>6785.003474</td>\n",
       "      <td>8338.906181</td>\n",
       "      <td>10965.76604</td>\n",
       "      <td>16198.04959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FI</th>\n",
       "      <td>3.58345</td>\n",
       "      <td>10.358927</td>\n",
       "      <td>11.626917</td>\n",
       "      <td>14.852022</td>\n",
       "      <td>13.666727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FL</th>\n",
       "      <td>7.298162</td>\n",
       "      <td>0.173229</td>\n",
       "      <td>7.70956</td>\n",
       "      <td>6.122162</td>\n",
       "      <td>8.153058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FR</th>\n",
       "      <td>1.73855</td>\n",
       "      <td>0.49706</td>\n",
       "      <td>0.97556</td>\n",
       "      <td>0.49706</td>\n",
       "      <td>48.50134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FS</th>\n",
       "      <td>0.094822</td>\n",
       "      <td>0.568932</td>\n",
       "      <td>1.198821</td>\n",
       "      <td>0.284466</td>\n",
       "      <td>0.121914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GB</th>\n",
       "      <td>11.339138</td>\n",
       "      <td>9.292698</td>\n",
       "      <td>37.077772</td>\n",
       "      <td>18.529584</td>\n",
       "      <td>16.408728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GE</th>\n",
       "      <td>72.611063</td>\n",
       "      <td>72.611063</td>\n",
       "      <td>88.609437</td>\n",
       "      <td>82.416803</td>\n",
       "      <td>146.109943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GF</th>\n",
       "      <td>2003.810319</td>\n",
       "      <td>27981.56275</td>\n",
       "      <td>13676.95781</td>\n",
       "      <td>2094.262452</td>\n",
       "      <td>8524.370502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GH</th>\n",
       "      <td>22.136229</td>\n",
       "      <td>29.13543</td>\n",
       "      <td>28.022851</td>\n",
       "      <td>39.948656</td>\n",
       "      <td>45.381316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GI</th>\n",
       "      <td>69.834944</td>\n",
       "      <td>32.131996</td>\n",
       "      <td>35.192676</td>\n",
       "      <td>90.493248</td>\n",
       "      <td>36.262628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GL</th>\n",
       "      <td>0.120343</td>\n",
       "      <td>21.978</td>\n",
       "      <td>0.196941</td>\n",
       "      <td>0.155829</td>\n",
       "      <td>0.096614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0             1             2             3             4\n",
       "Id     000ff2bfdfe9  007255e47698  013f2bd269f5  043ac50845d5  044fb8a146ec\n",
       "AB         0.209377      0.145282       0.47003      0.252107      0.380297\n",
       "AF       3109.03329     978.76416    2635.10654    3819.65177    3733.04844\n",
       "AH        85.200147     85.200147     85.200147    120.201618     85.200147\n",
       "AM        22.394407     36.968889     32.360553     77.112203     14.103738\n",
       "AR         8.138688      8.138688      8.138688      8.138688      8.138688\n",
       "AX         0.699861       3.63219       6.73284      3.685344      3.942255\n",
       "AY         0.025578      0.025578      0.025578      0.025578       0.05481\n",
       "AZ         9.812214      13.51779      12.82457     11.053708      3.396778\n",
       "BC         5.555634        1.2299        1.2299        1.2299     102.15198\n",
       "BD       4126.58731    5496.92824    5135.78024    4169.67738    5728.73412\n",
       "BN          22.5984       19.4205       26.4825       23.6577       24.0108\n",
       "BP       175.638726     155.86803    128.988531    237.282264    324.546318\n",
       "BQ       152.707705      14.75472     219.32016      11.05041    149.717165\n",
       "BR       823.928241     51.216883    482.141594     661.51864   6074.859475\n",
       "BZ       257.432377    257.432377    257.432377    257.432377    257.432377\n",
       "CB        47.223358     30.284345     32.563713     15.201914     82.213495\n",
       "CC         0.563481       0.48471      0.495852      0.717882      0.536467\n",
       "CD          23.3876     50.628208     85.955376      88.15936     72.644264\n",
       "CF         4.851915      6.085041      5.376488      2.347652     30.537722\n",
       "CH         0.023482      0.031442      0.036218      0.029054      0.025472\n",
       "CL         1.050225      1.113875      1.050225        1.4003      1.050225\n",
       "CR         0.069225        1.1178       0.70035      0.636075       0.69315\n",
       "CS        13.784111     28.310953     39.364743      41.11696     31.724726\n",
       "CU         1.302012      1.357182      1.009611      0.722727       0.82755\n",
       "CW        36.205956     37.476568     21.459644     21.530392      34.41536\n",
       "DA          69.0834      70.79836       70.8197      47.27586      74.06532\n",
       "DE       295.570575      178.5531    321.426625    196.607985     200.17816\n",
       "DF          0.23868       0.23868       0.23868       0.23868       0.23868\n",
       "DH         0.284232      0.363489      0.210441      0.292431      0.207708\n",
       "DI         89.24556    110.581815    120.056438     139.82457      97.92012\n",
       "DL         84.31664      75.74548      65.46984       71.5712      52.83888\n",
       "DN        29.657104        37.532     28.053464     24.354856     26.019912\n",
       "DU          5.31069      0.005518      1.289739      2.655345      1.144902\n",
       "DV          1.74307       1.74307       1.74307       1.74307       1.74307\n",
       "DY        23.187704     17.222328     36.861352     52.003884      9.064856\n",
       "EB         7.294176      4.926396      7.813674       7.38606       7.35072\n",
       "EE         1.987283      0.858603      8.146651      3.813326      3.490846\n",
       "EG       1433.16675    1111.28715   1494.076488   15691.55218     1403.6563\n",
       "EH         0.949104      0.003042      0.377208      0.614484      0.164268\n",
       "EJ                B             A             B             B             B\n",
       "EL         30.87942    109.125159    109.125159     31.674357    109.125159\n",
       "EP        78.526968     95.415086     78.526968     78.526968     91.994825\n",
       "EU         3.828384      52.26048      5.390628     31.323372     51.141336\n",
       "FC         13.39464     17.175984    224.207424     59.301984      29.10264\n",
       "FD        10.265073       0.29685      8.745201      7.884336       4.27464\n",
       "FE      9028.291921   6785.003474   8338.906181   10965.76604   16198.04959\n",
       "FI          3.58345     10.358927     11.626917     14.852022     13.666727\n",
       "FL         7.298162      0.173229       7.70956      6.122162      8.153058\n",
       "FR          1.73855       0.49706       0.97556       0.49706      48.50134\n",
       "FS         0.094822      0.568932      1.198821      0.284466      0.121914\n",
       "GB        11.339138      9.292698     37.077772     18.529584     16.408728\n",
       "GE        72.611063     72.611063     88.609437     82.416803    146.109943\n",
       "GF      2003.810319   27981.56275   13676.95781   2094.262452   8524.370502\n",
       "GH        22.136229      29.13543     28.022851     39.948656     45.381316\n",
       "GI        69.834944     32.131996     35.192676     90.493248     36.262628\n",
       "GL         0.120343        21.978      0.196941      0.155829      0.096614\n",
       "Class             1             0             0             0             1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"/kaggle/input/icr-identify-age-related-conditions/train.csv\")\n",
    "df.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d75ba9b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-04T11:36:26.469854Z",
     "iopub.status.busy": "2023-08-04T11:36:26.469472Z",
     "iopub.status.idle": "2023-08-04T11:36:26.499727Z",
     "shell.execute_reply": "2023-08-04T11:36:26.498679Z"
    },
    "papermill": {
     "duration": 0.037981,
     "end_time": "2023-08-04T11:36:26.502260",
     "exception": false,
     "start_time": "2023-08-04T11:36:26.464279",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 617 entries, 0 to 616\n",
      "Data columns (total 58 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Id      617 non-null    object \n",
      " 1   AB      617 non-null    float64\n",
      " 2   AF      617 non-null    float64\n",
      " 3   AH      617 non-null    float64\n",
      " 4   AM      617 non-null    float64\n",
      " 5   AR      617 non-null    float64\n",
      " 6   AX      617 non-null    float64\n",
      " 7   AY      617 non-null    float64\n",
      " 8   AZ      617 non-null    float64\n",
      " 9   BC      617 non-null    float64\n",
      " 10  BD      617 non-null    float64\n",
      " 11  BN      617 non-null    float64\n",
      " 12  BP      617 non-null    float64\n",
      " 13  BQ      557 non-null    float64\n",
      " 14  BR      617 non-null    float64\n",
      " 15  BZ      617 non-null    float64\n",
      " 16  CB      615 non-null    float64\n",
      " 17  CC      614 non-null    float64\n",
      " 18  CD      617 non-null    float64\n",
      " 19  CF      617 non-null    float64\n",
      " 20  CH      617 non-null    float64\n",
      " 21  CL      617 non-null    float64\n",
      " 22  CR      617 non-null    float64\n",
      " 23  CS      617 non-null    float64\n",
      " 24  CU      617 non-null    float64\n",
      " 25  CW      617 non-null    float64\n",
      " 26  DA      617 non-null    float64\n",
      " 27  DE      617 non-null    float64\n",
      " 28  DF      617 non-null    float64\n",
      " 29  DH      617 non-null    float64\n",
      " 30  DI      617 non-null    float64\n",
      " 31  DL      617 non-null    float64\n",
      " 32  DN      617 non-null    float64\n",
      " 33  DU      616 non-null    float64\n",
      " 34  DV      617 non-null    float64\n",
      " 35  DY      617 non-null    float64\n",
      " 36  EB      617 non-null    float64\n",
      " 37  EE      617 non-null    float64\n",
      " 38  EG      617 non-null    float64\n",
      " 39  EH      617 non-null    float64\n",
      " 40  EJ      617 non-null    int64  \n",
      " 41  EL      557 non-null    float64\n",
      " 42  EP      617 non-null    float64\n",
      " 43  EU      617 non-null    float64\n",
      " 44  FC      616 non-null    float64\n",
      " 45  FD      617 non-null    float64\n",
      " 46  FE      617 non-null    float64\n",
      " 47  FI      617 non-null    float64\n",
      " 48  FL      616 non-null    float64\n",
      " 49  FR      617 non-null    float64\n",
      " 50  FS      615 non-null    float64\n",
      " 51  GB      617 non-null    float64\n",
      " 52  GE      617 non-null    float64\n",
      " 53  GF      617 non-null    float64\n",
      " 54  GH      617 non-null    float64\n",
      " 55  GI      617 non-null    float64\n",
      " 56  GL      616 non-null    float64\n",
      " 57  Class   617 non-null    int64  \n",
      "dtypes: float64(55), int64(2), object(1)\n",
      "memory usage: 279.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df['EJ'] = df['EJ'].map({'A':0, 'B':1})\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6cad27e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-04T11:36:26.512281Z",
     "iopub.status.busy": "2023-08-04T11:36:26.511914Z",
     "iopub.status.idle": "2023-08-04T11:36:26.564153Z",
     "shell.execute_reply": "2023-08-04T11:36:26.562860Z"
    },
    "papermill": {
     "duration": 0.059768,
     "end_time": "2023-08-04T11:36:26.566296",
     "exception": false,
     "start_time": "2023-08-04T11:36:26.506528",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 617 entries, 0 to 616\n",
      "Data columns (total 58 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Id      617 non-null    object \n",
      " 1   AB      617 non-null    float64\n",
      " 2   AF      617 non-null    float64\n",
      " 3   AH      617 non-null    float64\n",
      " 4   AM      617 non-null    float64\n",
      " 5   AR      617 non-null    float64\n",
      " 6   AX      617 non-null    float64\n",
      " 7   AY      617 non-null    float64\n",
      " 8   AZ      617 non-null    float64\n",
      " 9   BC      617 non-null    float64\n",
      " 10  BD      617 non-null    float64\n",
      " 11  BN      617 non-null    float64\n",
      " 12  BP      617 non-null    float64\n",
      " 13  BQ      617 non-null    float64\n",
      " 14  BR      617 non-null    float64\n",
      " 15  BZ      617 non-null    float64\n",
      " 16  CB      617 non-null    float64\n",
      " 17  CC      617 non-null    float64\n",
      " 18  CD      617 non-null    float64\n",
      " 19  CF      617 non-null    float64\n",
      " 20  CH      617 non-null    float64\n",
      " 21  CL      617 non-null    float64\n",
      " 22  CR      617 non-null    float64\n",
      " 23  CS      617 non-null    float64\n",
      " 24  CU      617 non-null    float64\n",
      " 25  CW      617 non-null    float64\n",
      " 26  DA      617 non-null    float64\n",
      " 27  DE      617 non-null    float64\n",
      " 28  DF      617 non-null    float64\n",
      " 29  DH      617 non-null    float64\n",
      " 30  DI      617 non-null    float64\n",
      " 31  DL      617 non-null    float64\n",
      " 32  DN      617 non-null    float64\n",
      " 33  DU      617 non-null    float64\n",
      " 34  DV      617 non-null    float64\n",
      " 35  DY      617 non-null    float64\n",
      " 36  EB      617 non-null    float64\n",
      " 37  EE      617 non-null    float64\n",
      " 38  EG      617 non-null    float64\n",
      " 39  EH      617 non-null    float64\n",
      " 40  EJ      617 non-null    float64\n",
      " 41  EL      617 non-null    float64\n",
      " 42  EP      617 non-null    float64\n",
      " 43  EU      617 non-null    float64\n",
      " 44  FC      617 non-null    float64\n",
      " 45  FD      617 non-null    float64\n",
      " 46  FE      617 non-null    float64\n",
      " 47  FI      617 non-null    float64\n",
      " 48  FL      617 non-null    float64\n",
      " 49  FR      617 non-null    float64\n",
      " 50  FS      617 non-null    float64\n",
      " 51  GB      617 non-null    float64\n",
      " 52  GE      617 non-null    float64\n",
      " 53  GF      617 non-null    float64\n",
      " 54  GH      617 non-null    float64\n",
      " 55  GI      617 non-null    float64\n",
      " 56  GL      617 non-null    float64\n",
      " 57  Class   617 non-null    float64\n",
      "dtypes: float64(57), object(1)\n",
      "memory usage: 279.7+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <td>000ff2bfdfe9</td>\n",
       "      <td>007255e47698</td>\n",
       "      <td>013f2bd269f5</td>\n",
       "      <td>043ac50845d5</td>\n",
       "      <td>044fb8a146ec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AB</th>\n",
       "      <td>0.209377</td>\n",
       "      <td>0.145282</td>\n",
       "      <td>0.47003</td>\n",
       "      <td>0.252107</td>\n",
       "      <td>0.380297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AF</th>\n",
       "      <td>3109.03329</td>\n",
       "      <td>978.76416</td>\n",
       "      <td>2635.10654</td>\n",
       "      <td>3819.65177</td>\n",
       "      <td>3733.04844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AH</th>\n",
       "      <td>85.200147</td>\n",
       "      <td>85.200147</td>\n",
       "      <td>85.200147</td>\n",
       "      <td>120.201618</td>\n",
       "      <td>85.200147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AM</th>\n",
       "      <td>22.394407</td>\n",
       "      <td>36.968889</td>\n",
       "      <td>32.360553</td>\n",
       "      <td>77.112203</td>\n",
       "      <td>14.103738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>8.138688</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>8.138688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AX</th>\n",
       "      <td>0.699861</td>\n",
       "      <td>3.63219</td>\n",
       "      <td>6.73284</td>\n",
       "      <td>3.685344</td>\n",
       "      <td>3.942255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AY</th>\n",
       "      <td>0.025578</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>0.05481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>9.812214</td>\n",
       "      <td>13.51779</td>\n",
       "      <td>12.82457</td>\n",
       "      <td>11.053708</td>\n",
       "      <td>3.396778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BC</th>\n",
       "      <td>5.555634</td>\n",
       "      <td>1.2299</td>\n",
       "      <td>1.2299</td>\n",
       "      <td>1.2299</td>\n",
       "      <td>102.15198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BD</th>\n",
       "      <td>4126.58731</td>\n",
       "      <td>5496.92824</td>\n",
       "      <td>5135.78024</td>\n",
       "      <td>4169.67738</td>\n",
       "      <td>5728.73412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BN</th>\n",
       "      <td>22.5984</td>\n",
       "      <td>19.4205</td>\n",
       "      <td>26.4825</td>\n",
       "      <td>23.6577</td>\n",
       "      <td>24.0108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BP</th>\n",
       "      <td>175.638726</td>\n",
       "      <td>155.86803</td>\n",
       "      <td>128.988531</td>\n",
       "      <td>237.282264</td>\n",
       "      <td>324.546318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BQ</th>\n",
       "      <td>152.707705</td>\n",
       "      <td>14.75472</td>\n",
       "      <td>219.32016</td>\n",
       "      <td>11.05041</td>\n",
       "      <td>149.717165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BR</th>\n",
       "      <td>823.928241</td>\n",
       "      <td>51.216883</td>\n",
       "      <td>482.141594</td>\n",
       "      <td>661.51864</td>\n",
       "      <td>6074.859475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BZ</th>\n",
       "      <td>257.432377</td>\n",
       "      <td>257.432377</td>\n",
       "      <td>257.432377</td>\n",
       "      <td>257.432377</td>\n",
       "      <td>257.432377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB</th>\n",
       "      <td>47.223358</td>\n",
       "      <td>30.284345</td>\n",
       "      <td>32.563713</td>\n",
       "      <td>15.201914</td>\n",
       "      <td>82.213495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CC</th>\n",
       "      <td>0.563481</td>\n",
       "      <td>0.48471</td>\n",
       "      <td>0.495852</td>\n",
       "      <td>0.717882</td>\n",
       "      <td>0.536467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CD</th>\n",
       "      <td>23.3876</td>\n",
       "      <td>50.628208</td>\n",
       "      <td>85.955376</td>\n",
       "      <td>88.15936</td>\n",
       "      <td>72.644264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CF</th>\n",
       "      <td>4.851915</td>\n",
       "      <td>6.085041</td>\n",
       "      <td>5.376488</td>\n",
       "      <td>2.347652</td>\n",
       "      <td>30.537722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CH</th>\n",
       "      <td>0.023482</td>\n",
       "      <td>0.031442</td>\n",
       "      <td>0.036218</td>\n",
       "      <td>0.029054</td>\n",
       "      <td>0.025472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CL</th>\n",
       "      <td>1.050225</td>\n",
       "      <td>1.113875</td>\n",
       "      <td>1.050225</td>\n",
       "      <td>1.4003</td>\n",
       "      <td>1.050225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CR</th>\n",
       "      <td>0.069225</td>\n",
       "      <td>1.1178</td>\n",
       "      <td>0.70035</td>\n",
       "      <td>0.636075</td>\n",
       "      <td>0.69315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CS</th>\n",
       "      <td>13.784111</td>\n",
       "      <td>28.310953</td>\n",
       "      <td>39.364743</td>\n",
       "      <td>41.11696</td>\n",
       "      <td>31.724726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CU</th>\n",
       "      <td>1.302012</td>\n",
       "      <td>1.357182</td>\n",
       "      <td>1.009611</td>\n",
       "      <td>0.722727</td>\n",
       "      <td>0.82755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CW</th>\n",
       "      <td>36.205956</td>\n",
       "      <td>37.476568</td>\n",
       "      <td>21.459644</td>\n",
       "      <td>21.530392</td>\n",
       "      <td>34.41536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DA</th>\n",
       "      <td>69.0834</td>\n",
       "      <td>70.79836</td>\n",
       "      <td>70.8197</td>\n",
       "      <td>47.27586</td>\n",
       "      <td>74.06532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DE</th>\n",
       "      <td>295.570575</td>\n",
       "      <td>178.5531</td>\n",
       "      <td>321.426625</td>\n",
       "      <td>196.607985</td>\n",
       "      <td>200.17816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF</th>\n",
       "      <td>0.23868</td>\n",
       "      <td>0.23868</td>\n",
       "      <td>0.23868</td>\n",
       "      <td>0.23868</td>\n",
       "      <td>0.23868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DH</th>\n",
       "      <td>0.284232</td>\n",
       "      <td>0.363489</td>\n",
       "      <td>0.210441</td>\n",
       "      <td>0.292431</td>\n",
       "      <td>0.207708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DI</th>\n",
       "      <td>89.24556</td>\n",
       "      <td>110.581815</td>\n",
       "      <td>120.056438</td>\n",
       "      <td>139.82457</td>\n",
       "      <td>97.92012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DL</th>\n",
       "      <td>84.31664</td>\n",
       "      <td>75.74548</td>\n",
       "      <td>65.46984</td>\n",
       "      <td>71.5712</td>\n",
       "      <td>52.83888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DN</th>\n",
       "      <td>29.657104</td>\n",
       "      <td>37.532</td>\n",
       "      <td>28.053464</td>\n",
       "      <td>24.354856</td>\n",
       "      <td>26.019912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DU</th>\n",
       "      <td>5.31069</td>\n",
       "      <td>0.005518</td>\n",
       "      <td>1.289739</td>\n",
       "      <td>2.655345</td>\n",
       "      <td>1.144902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DV</th>\n",
       "      <td>1.74307</td>\n",
       "      <td>1.74307</td>\n",
       "      <td>1.74307</td>\n",
       "      <td>1.74307</td>\n",
       "      <td>1.74307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DY</th>\n",
       "      <td>23.187704</td>\n",
       "      <td>17.222328</td>\n",
       "      <td>36.861352</td>\n",
       "      <td>52.003884</td>\n",
       "      <td>9.064856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EB</th>\n",
       "      <td>7.294176</td>\n",
       "      <td>4.926396</td>\n",
       "      <td>7.813674</td>\n",
       "      <td>7.38606</td>\n",
       "      <td>7.35072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EE</th>\n",
       "      <td>1.987283</td>\n",
       "      <td>0.858603</td>\n",
       "      <td>8.146651</td>\n",
       "      <td>3.813326</td>\n",
       "      <td>3.490846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EG</th>\n",
       "      <td>1433.16675</td>\n",
       "      <td>1111.28715</td>\n",
       "      <td>1494.076488</td>\n",
       "      <td>15691.55218</td>\n",
       "      <td>1403.6563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EH</th>\n",
       "      <td>0.949104</td>\n",
       "      <td>0.003042</td>\n",
       "      <td>0.377208</td>\n",
       "      <td>0.614484</td>\n",
       "      <td>0.164268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EJ</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EL</th>\n",
       "      <td>30.87942</td>\n",
       "      <td>109.125159</td>\n",
       "      <td>109.125159</td>\n",
       "      <td>31.674357</td>\n",
       "      <td>109.125159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EP</th>\n",
       "      <td>78.526968</td>\n",
       "      <td>95.415086</td>\n",
       "      <td>78.526968</td>\n",
       "      <td>78.526968</td>\n",
       "      <td>91.994825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EU</th>\n",
       "      <td>3.828384</td>\n",
       "      <td>52.26048</td>\n",
       "      <td>5.390628</td>\n",
       "      <td>31.323372</td>\n",
       "      <td>51.141336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FC</th>\n",
       "      <td>13.39464</td>\n",
       "      <td>17.175984</td>\n",
       "      <td>224.207424</td>\n",
       "      <td>59.301984</td>\n",
       "      <td>29.10264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FD</th>\n",
       "      <td>10.265073</td>\n",
       "      <td>0.29685</td>\n",
       "      <td>8.745201</td>\n",
       "      <td>7.884336</td>\n",
       "      <td>4.27464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FE</th>\n",
       "      <td>9028.291921</td>\n",
       "      <td>6785.003474</td>\n",
       "      <td>8338.906181</td>\n",
       "      <td>10965.76604</td>\n",
       "      <td>16198.04959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FI</th>\n",
       "      <td>3.58345</td>\n",
       "      <td>10.358927</td>\n",
       "      <td>11.626917</td>\n",
       "      <td>14.852022</td>\n",
       "      <td>13.666727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FL</th>\n",
       "      <td>7.298162</td>\n",
       "      <td>0.173229</td>\n",
       "      <td>7.70956</td>\n",
       "      <td>6.122162</td>\n",
       "      <td>8.153058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FR</th>\n",
       "      <td>1.73855</td>\n",
       "      <td>0.49706</td>\n",
       "      <td>0.97556</td>\n",
       "      <td>0.49706</td>\n",
       "      <td>48.50134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FS</th>\n",
       "      <td>0.094822</td>\n",
       "      <td>0.568932</td>\n",
       "      <td>1.198821</td>\n",
       "      <td>0.284466</td>\n",
       "      <td>0.121914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GB</th>\n",
       "      <td>11.339138</td>\n",
       "      <td>9.292698</td>\n",
       "      <td>37.077772</td>\n",
       "      <td>18.529584</td>\n",
       "      <td>16.408728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GE</th>\n",
       "      <td>72.611063</td>\n",
       "      <td>72.611063</td>\n",
       "      <td>88.609437</td>\n",
       "      <td>82.416803</td>\n",
       "      <td>146.109943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GF</th>\n",
       "      <td>2003.810319</td>\n",
       "      <td>27981.56275</td>\n",
       "      <td>13676.95781</td>\n",
       "      <td>2094.262452</td>\n",
       "      <td>8524.370502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GH</th>\n",
       "      <td>22.136229</td>\n",
       "      <td>29.13543</td>\n",
       "      <td>28.022851</td>\n",
       "      <td>39.948656</td>\n",
       "      <td>45.381316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GI</th>\n",
       "      <td>69.834944</td>\n",
       "      <td>32.131996</td>\n",
       "      <td>35.192676</td>\n",
       "      <td>90.493248</td>\n",
       "      <td>36.262628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GL</th>\n",
       "      <td>0.120343</td>\n",
       "      <td>21.978</td>\n",
       "      <td>0.196941</td>\n",
       "      <td>0.155829</td>\n",
       "      <td>0.096614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0             1             2             3             4\n",
       "Id     000ff2bfdfe9  007255e47698  013f2bd269f5  043ac50845d5  044fb8a146ec\n",
       "AB         0.209377      0.145282       0.47003      0.252107      0.380297\n",
       "AF       3109.03329     978.76416    2635.10654    3819.65177    3733.04844\n",
       "AH        85.200147     85.200147     85.200147    120.201618     85.200147\n",
       "AM        22.394407     36.968889     32.360553     77.112203     14.103738\n",
       "AR         8.138688      8.138688      8.138688      8.138688      8.138688\n",
       "AX         0.699861       3.63219       6.73284      3.685344      3.942255\n",
       "AY         0.025578      0.025578      0.025578      0.025578       0.05481\n",
       "AZ         9.812214      13.51779      12.82457     11.053708      3.396778\n",
       "BC         5.555634        1.2299        1.2299        1.2299     102.15198\n",
       "BD       4126.58731    5496.92824    5135.78024    4169.67738    5728.73412\n",
       "BN          22.5984       19.4205       26.4825       23.6577       24.0108\n",
       "BP       175.638726     155.86803    128.988531    237.282264    324.546318\n",
       "BQ       152.707705      14.75472     219.32016      11.05041    149.717165\n",
       "BR       823.928241     51.216883    482.141594     661.51864   6074.859475\n",
       "BZ       257.432377    257.432377    257.432377    257.432377    257.432377\n",
       "CB        47.223358     30.284345     32.563713     15.201914     82.213495\n",
       "CC         0.563481       0.48471      0.495852      0.717882      0.536467\n",
       "CD          23.3876     50.628208     85.955376      88.15936     72.644264\n",
       "CF         4.851915      6.085041      5.376488      2.347652     30.537722\n",
       "CH         0.023482      0.031442      0.036218      0.029054      0.025472\n",
       "CL         1.050225      1.113875      1.050225        1.4003      1.050225\n",
       "CR         0.069225        1.1178       0.70035      0.636075       0.69315\n",
       "CS        13.784111     28.310953     39.364743      41.11696     31.724726\n",
       "CU         1.302012      1.357182      1.009611      0.722727       0.82755\n",
       "CW        36.205956     37.476568     21.459644     21.530392      34.41536\n",
       "DA          69.0834      70.79836       70.8197      47.27586      74.06532\n",
       "DE       295.570575      178.5531    321.426625    196.607985     200.17816\n",
       "DF          0.23868       0.23868       0.23868       0.23868       0.23868\n",
       "DH         0.284232      0.363489      0.210441      0.292431      0.207708\n",
       "DI         89.24556    110.581815    120.056438     139.82457      97.92012\n",
       "DL         84.31664      75.74548      65.46984       71.5712      52.83888\n",
       "DN        29.657104        37.532     28.053464     24.354856     26.019912\n",
       "DU          5.31069      0.005518      1.289739      2.655345      1.144902\n",
       "DV          1.74307       1.74307       1.74307       1.74307       1.74307\n",
       "DY        23.187704     17.222328     36.861352     52.003884      9.064856\n",
       "EB         7.294176      4.926396      7.813674       7.38606       7.35072\n",
       "EE         1.987283      0.858603      8.146651      3.813326      3.490846\n",
       "EG       1433.16675    1111.28715   1494.076488   15691.55218     1403.6563\n",
       "EH         0.949104      0.003042      0.377208      0.614484      0.164268\n",
       "EJ              1.0           0.0           1.0           1.0           1.0\n",
       "EL         30.87942    109.125159    109.125159     31.674357    109.125159\n",
       "EP        78.526968     95.415086     78.526968     78.526968     91.994825\n",
       "EU         3.828384      52.26048      5.390628     31.323372     51.141336\n",
       "FC         13.39464     17.175984    224.207424     59.301984      29.10264\n",
       "FD        10.265073       0.29685      8.745201      7.884336       4.27464\n",
       "FE      9028.291921   6785.003474   8338.906181   10965.76604   16198.04959\n",
       "FI          3.58345     10.358927     11.626917     14.852022     13.666727\n",
       "FL         7.298162      0.173229       7.70956      6.122162      8.153058\n",
       "FR          1.73855       0.49706       0.97556       0.49706      48.50134\n",
       "FS         0.094822      0.568932      1.198821      0.284466      0.121914\n",
       "GB        11.339138      9.292698     37.077772     18.529584     16.408728\n",
       "GE        72.611063     72.611063     88.609437     82.416803    146.109943\n",
       "GF      2003.810319   27981.56275   13676.95781   2094.262452   8524.370502\n",
       "GH        22.136229      29.13543     28.022851     39.948656     45.381316\n",
       "GI        69.834944     32.131996     35.192676     90.493248     36.262628\n",
       "GL         0.120343        21.978      0.196941      0.155829      0.096614\n",
       "Class           1.0           0.0           0.0           0.0           1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use forward fill to replace NaN with the previous valid value in each column.\n",
    "df.fillna(method='ffill', inplace=True)\n",
    "\n",
    "df = df.astype({'EJ':'float64', 'Class': 'float64'})\n",
    "\n",
    "print(df.info())\n",
    "df.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e42c12d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-04T11:36:26.578426Z",
     "iopub.status.busy": "2023-08-04T11:36:26.578013Z",
     "iopub.status.idle": "2023-08-04T11:36:27.977847Z",
     "shell.execute_reply": "2023-08-04T11:36:27.976573Z"
    },
    "papermill": {
     "duration": 1.408952,
     "end_time": "2023-08-04T11:36:27.980356",
     "exception": false,
     "start_time": "2023-08-04T11:36:26.571404",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    509\n",
      "1.0    108\n",
      "Name: Class, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.6060903732809431, 1: 2.8564814814814814}\n"
     ]
    }
   ],
   "source": [
    "cls = df['Class']\n",
    "# Count the occurrences of each unique value in 'col'\n",
    "value_counts = cls.value_counts()\n",
    "print(value_counts)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(2, 2))\n",
    "# Create a pie chart\n",
    "plt.pie(value_counts, labels=value_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "# Equal aspect ratio ensures that pie is drawn as a circle\n",
    "plt.axis('equal')\n",
    "# Add a title\n",
    "plt.title(\"Pie Chart for df['Class']\")\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Handle class imbalance\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight('balanced', classes=[0, 1], y=cls)\n",
    "# Convert class weights to a dictionary format required by LightGBM\n",
    "class_weight_dict = {0: class_weights[0], 1: class_weights[1]}\n",
    "print(class_weight_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dc0bb90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-04T11:36:27.993794Z",
     "iopub.status.busy": "2023-08-04T11:36:27.993270Z",
     "iopub.status.idle": "2023-08-04T11:36:28.050053Z",
     "shell.execute_reply": "2023-08-04T11:36:28.048822Z"
    },
    "papermill": {
     "duration": 0.066681,
     "end_time": "2023-08-04T11:36:28.052676",
     "exception": false,
     "start_time": "2023-08-04T11:36:27.985995",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AB</th>\n",
       "      <td>0.021082</td>\n",
       "      <td>0.010541</td>\n",
       "      <td>0.063949</td>\n",
       "      <td>0.028110</td>\n",
       "      <td>0.049192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AF</th>\n",
       "      <td>0.102347</td>\n",
       "      <td>0.027589</td>\n",
       "      <td>0.085715</td>\n",
       "      <td>0.127285</td>\n",
       "      <td>0.124246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AH</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019180</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AM</th>\n",
       "      <td>0.030632</td>\n",
       "      <td>0.053864</td>\n",
       "      <td>0.046519</td>\n",
       "      <td>0.117854</td>\n",
       "      <td>0.017417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AX</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078048</td>\n",
       "      <td>0.160575</td>\n",
       "      <td>0.079462</td>\n",
       "      <td>0.086300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AY</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>0.180337</td>\n",
       "      <td>0.284500</td>\n",
       "      <td>0.265013</td>\n",
       "      <td>0.215235</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BC</th>\n",
       "      <td>0.002958</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BD</th>\n",
       "      <td>0.047364</td>\n",
       "      <td>0.074042</td>\n",
       "      <td>0.067011</td>\n",
       "      <td>0.048203</td>\n",
       "      <td>0.078555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BN</th>\n",
       "      <td>0.654545</td>\n",
       "      <td>0.490909</td>\n",
       "      <td>0.854545</td>\n",
       "      <td>0.709091</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BP</th>\n",
       "      <td>0.043240</td>\n",
       "      <td>0.034915</td>\n",
       "      <td>0.023597</td>\n",
       "      <td>0.069197</td>\n",
       "      <td>0.105942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BQ</th>\n",
       "      <td>0.440929</td>\n",
       "      <td>0.039100</td>\n",
       "      <td>0.634957</td>\n",
       "      <td>0.028310</td>\n",
       "      <td>0.432218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BR</th>\n",
       "      <td>0.004312</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002405</td>\n",
       "      <td>0.003406</td>\n",
       "      <td>0.033614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BZ</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB</th>\n",
       "      <td>0.015372</td>\n",
       "      <td>0.007873</td>\n",
       "      <td>0.008882</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>0.030861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CC</th>\n",
       "      <td>0.098469</td>\n",
       "      <td>0.078406</td>\n",
       "      <td>0.081244</td>\n",
       "      <td>0.137796</td>\n",
       "      <td>0.091589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CD</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044646</td>\n",
       "      <td>0.102545</td>\n",
       "      <td>0.106158</td>\n",
       "      <td>0.080729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CF</th>\n",
       "      <td>0.021656</td>\n",
       "      <td>0.027807</td>\n",
       "      <td>0.024273</td>\n",
       "      <td>0.009163</td>\n",
       "      <td>0.149792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CH</th>\n",
       "      <td>0.091892</td>\n",
       "      <td>0.127928</td>\n",
       "      <td>0.149550</td>\n",
       "      <td>0.117117</td>\n",
       "      <td>0.100901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CL</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002077</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011426</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CR</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.353002</td>\n",
       "      <td>0.212468</td>\n",
       "      <td>0.190830</td>\n",
       "      <td>0.210044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CS</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057157</td>\n",
       "      <td>0.100648</td>\n",
       "      <td>0.107542</td>\n",
       "      <td>0.070588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CU</th>\n",
       "      <td>0.241834</td>\n",
       "      <td>0.253295</td>\n",
       "      <td>0.181089</td>\n",
       "      <td>0.121490</td>\n",
       "      <td>0.143266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CW</th>\n",
       "      <td>0.507476</td>\n",
       "      <td>0.529577</td>\n",
       "      <td>0.250979</td>\n",
       "      <td>0.252209</td>\n",
       "      <td>0.476331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DA</th>\n",
       "      <td>0.305651</td>\n",
       "      <td>0.314082</td>\n",
       "      <td>0.314187</td>\n",
       "      <td>0.198449</td>\n",
       "      <td>0.330142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DE</th>\n",
       "      <td>0.125554</td>\n",
       "      <td>0.068953</td>\n",
       "      <td>0.138061</td>\n",
       "      <td>0.077686</td>\n",
       "      <td>0.079413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DH</th>\n",
       "      <td>0.238606</td>\n",
       "      <td>0.316354</td>\n",
       "      <td>0.166220</td>\n",
       "      <td>0.246649</td>\n",
       "      <td>0.163539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DI</th>\n",
       "      <td>0.029338</td>\n",
       "      <td>0.050913</td>\n",
       "      <td>0.060493</td>\n",
       "      <td>0.080483</td>\n",
       "      <td>0.038109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DL</th>\n",
       "      <td>0.234167</td>\n",
       "      <td>0.207033</td>\n",
       "      <td>0.174504</td>\n",
       "      <td>0.193819</td>\n",
       "      <td>0.134519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DN</th>\n",
       "      <td>0.412931</td>\n",
       "      <td>0.552387</td>\n",
       "      <td>0.384532</td>\n",
       "      <td>0.319033</td>\n",
       "      <td>0.348520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DU</th>\n",
       "      <td>0.032880</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007959</td>\n",
       "      <td>0.016423</td>\n",
       "      <td>0.007062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DV</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DY</th>\n",
       "      <td>0.147697</td>\n",
       "      <td>0.108335</td>\n",
       "      <td>0.237922</td>\n",
       "      <td>0.337839</td>\n",
       "      <td>0.054508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EB</th>\n",
       "      <td>0.026299</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032069</td>\n",
       "      <td>0.027320</td>\n",
       "      <td>0.026927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EE</th>\n",
       "      <td>0.094302</td>\n",
       "      <td>0.031732</td>\n",
       "      <td>0.435754</td>\n",
       "      <td>0.195531</td>\n",
       "      <td>0.177654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EG</th>\n",
       "      <td>0.041505</td>\n",
       "      <td>0.030797</td>\n",
       "      <td>0.043532</td>\n",
       "      <td>0.515865</td>\n",
       "      <td>0.040524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EH</th>\n",
       "      <td>0.022225</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008790</td>\n",
       "      <td>0.014364</td>\n",
       "      <td>0.003788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EJ</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EL</th>\n",
       "      <td>0.245682</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.253346</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EP</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017144</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EU</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007454</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>0.004232</td>\n",
       "      <td>0.007282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FC</th>\n",
       "      <td>0.001939</td>\n",
       "      <td>0.003189</td>\n",
       "      <td>0.071672</td>\n",
       "      <td>0.017124</td>\n",
       "      <td>0.007135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FD</th>\n",
       "      <td>0.006316</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005353</td>\n",
       "      <td>0.004807</td>\n",
       "      <td>0.002520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FE</th>\n",
       "      <td>0.052697</td>\n",
       "      <td>0.036862</td>\n",
       "      <td>0.047831</td>\n",
       "      <td>0.066374</td>\n",
       "      <td>0.103309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FI</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.209978</td>\n",
       "      <td>0.249274</td>\n",
       "      <td>0.349223</td>\n",
       "      <td>0.312489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FL</th>\n",
       "      <td>0.051720</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054706</td>\n",
       "      <td>0.043183</td>\n",
       "      <td>0.057926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FR</th>\n",
       "      <td>0.000998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FS</th>\n",
       "      <td>0.000866</td>\n",
       "      <td>0.016014</td>\n",
       "      <td>0.036139</td>\n",
       "      <td>0.006925</td>\n",
       "      <td>0.001731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GB</th>\n",
       "      <td>0.054959</td>\n",
       "      <td>0.039418</td>\n",
       "      <td>0.250424</td>\n",
       "      <td>0.109565</td>\n",
       "      <td>0.093459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GE</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011229</td>\n",
       "      <td>0.006882</td>\n",
       "      <td>0.051588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GF</th>\n",
       "      <td>0.013846</td>\n",
       "      <td>0.194527</td>\n",
       "      <td>0.095035</td>\n",
       "      <td>0.014475</td>\n",
       "      <td>0.059198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GH</th>\n",
       "      <td>0.176983</td>\n",
       "      <td>0.274495</td>\n",
       "      <td>0.258994</td>\n",
       "      <td>0.425143</td>\n",
       "      <td>0.500829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GI</th>\n",
       "      <td>0.362261</td>\n",
       "      <td>0.164135</td>\n",
       "      <td>0.180218</td>\n",
       "      <td>0.470820</td>\n",
       "      <td>0.185841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GL</th>\n",
       "      <td>0.005425</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.008910</td>\n",
       "      <td>0.007039</td>\n",
       "      <td>0.004345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4\n",
       "AB     0.021082  0.010541  0.063949  0.028110  0.049192\n",
       "AF     0.102347  0.027589  0.085715  0.127285  0.124246\n",
       "AH     0.000000  0.000000  0.000000  0.019180  0.000000\n",
       "AM     0.030632  0.053864  0.046519  0.117854  0.017417\n",
       "AR     0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "AX     0.000000  0.078048  0.160575  0.079462  0.086300\n",
       "AY     0.000000  0.000000  0.000000  0.000000  0.002841\n",
       "AZ     0.180337  0.284500  0.265013  0.215235  0.000000\n",
       "BC     0.002958  0.000000  0.000000  0.000000  0.069008\n",
       "BD     0.047364  0.074042  0.067011  0.048203  0.078555\n",
       "BN     0.654545  0.490909  0.854545  0.709091  0.727273\n",
       "BP     0.043240  0.034915  0.023597  0.069197  0.105942\n",
       "BQ     0.440929  0.039100  0.634957  0.028310  0.432218\n",
       "BR     0.004312  0.000000  0.002405  0.003406  0.033614\n",
       "BZ     0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "CB     0.015372  0.007873  0.008882  0.001196  0.030861\n",
       "CC     0.098469  0.078406  0.081244  0.137796  0.091589\n",
       "CD     0.000000  0.044646  0.102545  0.106158  0.080729\n",
       "CF     0.021656  0.027807  0.024273  0.009163  0.149792\n",
       "CH     0.091892  0.127928  0.149550  0.117117  0.100901\n",
       "CL     0.000000  0.002077  0.000000  0.011426  0.000000\n",
       "CR     0.000000  0.353002  0.212468  0.190830  0.210044\n",
       "CS     0.000000  0.057157  0.100648  0.107542  0.070588\n",
       "CU     0.241834  0.253295  0.181089  0.121490  0.143266\n",
       "CW     0.507476  0.529577  0.250979  0.252209  0.476331\n",
       "DA     0.305651  0.314082  0.314187  0.198449  0.330142\n",
       "DE     0.125554  0.068953  0.138061  0.077686  0.079413\n",
       "DF     0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "DH     0.238606  0.316354  0.166220  0.246649  0.163539\n",
       "DI     0.029338  0.050913  0.060493  0.080483  0.038109\n",
       "DL     0.234167  0.207033  0.174504  0.193819  0.134519\n",
       "DN     0.412931  0.552387  0.384532  0.319033  0.348520\n",
       "DU     0.032880  0.000000  0.007959  0.016423  0.007062\n",
       "DV     0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "DY     0.147697  0.108335  0.237922  0.337839  0.054508\n",
       "EB     0.026299  0.000000  0.032069  0.027320  0.026927\n",
       "EE     0.094302  0.031732  0.435754  0.195531  0.177654\n",
       "EG     0.041505  0.030797  0.043532  0.515865  0.040524\n",
       "EH     0.022225  0.000000  0.008790  0.014364  0.003788\n",
       "EJ     1.000000  0.000000  1.000000  1.000000  1.000000\n",
       "EL     0.245682  1.000000  1.000000  0.253346  1.000000\n",
       "EP     0.000000  0.017144  0.000000  0.000000  0.013672\n",
       "EU     0.000000  0.007454  0.000240  0.004232  0.007282\n",
       "FC     0.001939  0.003189  0.071672  0.017124  0.007135\n",
       "FD     0.006316  0.000000  0.005353  0.004807  0.002520\n",
       "FE     0.052697  0.036862  0.047831  0.066374  0.103309\n",
       "FI     0.000000  0.209978  0.249274  0.349223  0.312489\n",
       "FL     0.051720  0.000000  0.054706  0.043183  0.057926\n",
       "FR     0.000998  0.000000  0.000385  0.000000  0.038597\n",
       "FS     0.000866  0.016014  0.036139  0.006925  0.001731\n",
       "GB     0.054959  0.039418  0.250424  0.109565  0.093459\n",
       "GE     0.000000  0.000000  0.011229  0.006882  0.051588\n",
       "GF     0.013846  0.194527  0.095035  0.014475  0.059198\n",
       "GH     0.176983  0.274495  0.258994  0.425143  0.500829\n",
       "GI     0.362261  0.164135  0.180218  0.470820  0.185841\n",
       "GL     0.005425  1.000000  0.008910  0.007039  0.004345\n",
       "Class  1.000000  0.000000  0.000000  0.000000  1.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pr = df.drop(['Id'], axis = 1)\n",
    "\n",
    "# Normalizing to the range of 0 to 1\n",
    "min_val = df_pr.min()\n",
    "max_val = df_pr.max()\n",
    "df_norm = (df_pr - min_val) / (max_val - min_val)\n",
    "\n",
    "df_norm.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "503593ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-04T11:36:28.069557Z",
     "iopub.status.busy": "2023-08-04T11:36:28.069058Z",
     "iopub.status.idle": "2023-08-04T11:36:28.184690Z",
     "shell.execute_reply": "2023-08-04T11:36:28.183217Z"
    },
    "papermill": {
     "duration": 0.128051,
     "end_time": "2023-08-04T11:36:28.187446",
     "exception": false,
     "start_time": "2023-08-04T11:36:28.059395",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "def balanced_log_loss(y_true, y_pred):\n",
    "#     n_true = np.count_nonzero(y_true==1)\n",
    "    y_true = np.array(y_true).astype(int)  # Convert y_true to a NumPy array with integer data type\n",
    "    nc = np.bincount(y_true)\n",
    "    return log_loss(y_true, y_pred, sample_weight = 1.0/nc[y_true], eps=1e-15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1b9ec5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-04T11:36:28.203362Z",
     "iopub.status.busy": "2023-08-04T11:36:28.202900Z",
     "iopub.status.idle": "2023-08-04T11:36:31.290986Z",
     "shell.execute_reply": "2023-08-04T11:36:31.289356Z"
    },
    "papermill": {
     "duration": 3.098208,
     "end_time": "2023-08-04T11:36:31.293324",
     "exception": false,
     "start_time": "2023-08-04T11:36:28.195116",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM Classifier\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 92, number of negative: 401\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001422 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6898\n",
      "[LightGBM] [Info] Number of data points in the train set: 493, number of used features: 56\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.186613 -> initscore=-1.472173\n",
      "[LightGBM] [Info] Start training from score -1.472173\n",
      "[1]\ttraining's binary_logloss: 0.476009\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\ttraining's binary_logloss: 0.470988\n",
      "[3]\ttraining's binary_logloss: 0.466192\n",
      "[4]\ttraining's binary_logloss: 0.461537\n",
      "[5]\ttraining's binary_logloss: 0.457598\n",
      "[6]\ttraining's binary_logloss: 0.453537\n",
      "[7]\ttraining's binary_logloss: 0.449646\n",
      "[8]\ttraining's binary_logloss: 0.445913\n",
      "[9]\ttraining's binary_logloss: 0.442329\n",
      "[10]\ttraining's binary_logloss: 0.438886\n",
      "[11]\ttraining's binary_logloss: 0.435503\n",
      "[12]\ttraining's binary_logloss: 0.43298\n",
      "[13]\ttraining's binary_logloss: 0.430133\n",
      "[14]\ttraining's binary_logloss: 0.427052\n",
      "[15]\ttraining's binary_logloss: 0.424085\n",
      "[16]\ttraining's binary_logloss: 0.422352\n",
      "[17]\ttraining's binary_logloss: 0.419663\n",
      "[18]\ttraining's binary_logloss: 0.417073\n",
      "[19]\ttraining's binary_logloss: 0.415506\n",
      "[20]\ttraining's binary_logloss: 0.413147\n",
      "[21]\ttraining's binary_logloss: 0.410511\n",
      "[22]\ttraining's binary_logloss: 0.407963\n",
      "[23]\ttraining's binary_logloss: 0.405498\n",
      "[24]\ttraining's binary_logloss: 0.403114\n",
      "[25]\ttraining's binary_logloss: 0.400802\n",
      "[26]\ttraining's binary_logloss: 0.39878\n",
      "[27]\ttraining's binary_logloss: 0.396783\n",
      "[28]\ttraining's binary_logloss: 0.394894\n",
      "[29]\ttraining's binary_logloss: 0.393072\n",
      "[30]\ttraining's binary_logloss: 0.391313\n",
      "[31]\ttraining's binary_logloss: 0.389393\n",
      "[32]\ttraining's binary_logloss: 0.387534\n",
      "[33]\ttraining's binary_logloss: 0.385692\n",
      "[34]\ttraining's binary_logloss: 0.384279\n",
      "[35]\ttraining's binary_logloss: 0.38256\n",
      "[36]\ttraining's binary_logloss: 0.381309\n",
      "[37]\ttraining's binary_logloss: 0.379818\n",
      "[38]\ttraining's binary_logloss: 0.378778\n",
      "[39]\ttraining's binary_logloss: 0.377429\n",
      "[40]\ttraining's binary_logloss: 0.376453\n",
      "[41]\ttraining's binary_logloss: 0.374984\n",
      "[42]\ttraining's binary_logloss: 0.373564\n",
      "[43]\ttraining's binary_logloss: 0.372193\n",
      "[44]\ttraining's binary_logloss: 0.370867\n",
      "[45]\ttraining's binary_logloss: 0.369586\n",
      "[46]\ttraining's binary_logloss: 0.368333\n",
      "[47]\ttraining's binary_logloss: 0.367118\n",
      "[48]\ttraining's binary_logloss: 0.365824\n",
      "[49]\ttraining's binary_logloss: 0.364594\n",
      "[50]\ttraining's binary_logloss: 0.363443\n",
      "[51]\ttraining's binary_logloss: 0.362456\n",
      "[52]\ttraining's binary_logloss: 0.361507\n",
      "[53]\ttraining's binary_logloss: 0.360749\n",
      "[54]\ttraining's binary_logloss: 0.360046\n",
      "[55]\ttraining's binary_logloss: 0.359242\n",
      "[56]\ttraining's binary_logloss: 0.358244\n",
      "[57]\ttraining's binary_logloss: 0.357135\n",
      "[58]\ttraining's binary_logloss: 0.356169\n",
      "[59]\ttraining's binary_logloss: 0.355112\n",
      "[60]\ttraining's binary_logloss: 0.354061\n",
      "[61]\ttraining's binary_logloss: 0.353169\n",
      "[62]\ttraining's binary_logloss: 0.352521\n",
      "[63]\ttraining's binary_logloss: 0.351599\n",
      "[64]\ttraining's binary_logloss: 0.350912\n",
      "[65]\ttraining's binary_logloss: 0.350032\n",
      "[66]\ttraining's binary_logloss: 0.34921\n",
      "[67]\ttraining's binary_logloss: 0.348501\n",
      "[68]\ttraining's binary_logloss: 0.347726\n",
      "[69]\ttraining's binary_logloss: 0.347063\n",
      "[70]\ttraining's binary_logloss: 0.346415\n",
      "[71]\ttraining's binary_logloss: 0.345627\n",
      "[72]\ttraining's binary_logloss: 0.344863\n",
      "[73]\ttraining's binary_logloss: 0.344123\n",
      "[74]\ttraining's binary_logloss: 0.343406\n",
      "[75]\ttraining's binary_logloss: 0.342711\n",
      "[76]\ttraining's binary_logloss: 0.342485\n",
      "[77]\ttraining's binary_logloss: 0.342298\n",
      "[78]\ttraining's binary_logloss: 0.342101\n",
      "[79]\ttraining's binary_logloss: 0.34192\n",
      "[80]\ttraining's binary_logloss: 0.341756\n",
      "[81]\ttraining's binary_logloss: 0.341051\n",
      "[82]\ttraining's binary_logloss: 0.340368\n",
      "[83]\ttraining's binary_logloss: 0.339708\n",
      "[84]\ttraining's binary_logloss: 0.339146\n",
      "[85]\ttraining's binary_logloss: 0.338644\n",
      "[86]\ttraining's binary_logloss: 0.337905\n",
      "[87]\ttraining's binary_logloss: 0.337128\n",
      "[88]\ttraining's binary_logloss: 0.336353\n",
      "[89]\ttraining's binary_logloss: 0.335656\n",
      "[90]\ttraining's binary_logloss: 0.334913\n",
      "[91]\ttraining's binary_logloss: 0.334237\n",
      "[92]\ttraining's binary_logloss: 0.333479\n",
      "[93]\ttraining's binary_logloss: 0.33283\n",
      "[94]\ttraining's binary_logloss: 0.332201\n",
      "[95]\ttraining's binary_logloss: 0.331594\n",
      "[96]\ttraining's binary_logloss: 0.330803\n",
      "[97]\ttraining's binary_logloss: 0.330033\n",
      "[98]\ttraining's binary_logloss: 0.329289\n",
      "[99]\ttraining's binary_logloss: 0.328532\n",
      "[100]\ttraining's binary_logloss: 0.327675\n",
      "[101]\ttraining's binary_logloss: 0.326956\n",
      "[102]\ttraining's binary_logloss: 0.326257\n",
      "[103]\ttraining's binary_logloss: 0.325516\n",
      "[104]\ttraining's binary_logloss: 0.324843\n",
      "[105]\ttraining's binary_logloss: 0.324189\n",
      "[106]\ttraining's binary_logloss: 0.323767\n",
      "[107]\ttraining's binary_logloss: 0.32336\n",
      "[108]\ttraining's binary_logloss: 0.322682\n",
      "[109]\ttraining's binary_logloss: 0.322008\n",
      "[110]\ttraining's binary_logloss: 0.321619\n",
      "[111]\ttraining's binary_logloss: 0.320984\n",
      "[112]\ttraining's binary_logloss: 0.320476\n",
      "[113]\ttraining's binary_logloss: 0.319887\n",
      "[114]\ttraining's binary_logloss: 0.319275\n",
      "[115]\ttraining's binary_logloss: 0.318679\n",
      "[116]\ttraining's binary_logloss: 0.318024\n",
      "[117]\ttraining's binary_logloss: 0.317488\n",
      "[118]\ttraining's binary_logloss: 0.316969\n",
      "[119]\ttraining's binary_logloss: 0.316466\n",
      "[120]\ttraining's binary_logloss: 0.316004\n",
      "[121]\ttraining's binary_logloss: 0.315344\n",
      "[122]\ttraining's binary_logloss: 0.31504\n",
      "[123]\ttraining's binary_logloss: 0.314578\n",
      "[124]\ttraining's binary_logloss: 0.314159\n",
      "[125]\ttraining's binary_logloss: 0.313522\n",
      "[126]\ttraining's binary_logloss: 0.313071\n",
      "[127]\ttraining's binary_logloss: 0.312721\n",
      "[128]\ttraining's binary_logloss: 0.312214\n",
      "[129]\ttraining's binary_logloss: 0.311736\n",
      "[130]\ttraining's binary_logloss: 0.311248\n",
      "[131]\ttraining's binary_logloss: 0.310929\n",
      "[132]\ttraining's binary_logloss: 0.310367\n",
      "[133]\ttraining's binary_logloss: 0.309723\n",
      "[134]\ttraining's binary_logloss: 0.309178\n",
      "[135]\ttraining's binary_logloss: 0.308645\n",
      "[136]\ttraining's binary_logloss: 0.308292\n",
      "[137]\ttraining's binary_logloss: 0.307953\n",
      "[138]\ttraining's binary_logloss: 0.307468\n",
      "[139]\ttraining's binary_logloss: 0.307033\n",
      "[140]\ttraining's binary_logloss: 0.306722\n",
      "[141]\ttraining's binary_logloss: 0.306107\n",
      "[142]\ttraining's binary_logloss: 0.305559\n",
      "[143]\ttraining's binary_logloss: 0.305022\n",
      "[144]\ttraining's binary_logloss: 0.304497\n",
      "[145]\ttraining's binary_logloss: 0.303901\n",
      "[146]\ttraining's binary_logloss: 0.303407\n",
      "[147]\ttraining's binary_logloss: 0.302882\n",
      "[148]\ttraining's binary_logloss: 0.30237\n",
      "[149]\ttraining's binary_logloss: 0.301864\n",
      "[150]\ttraining's binary_logloss: 0.301371\n",
      "[151]\ttraining's binary_logloss: 0.300683\n",
      "[152]\ttraining's binary_logloss: 0.300205\n",
      "[153]\ttraining's binary_logloss: 0.299687\n",
      "[154]\ttraining's binary_logloss: 0.298867\n",
      "[155]\ttraining's binary_logloss: 0.298064\n",
      "[156]\ttraining's binary_logloss: 0.297427\n",
      "[157]\ttraining's binary_logloss: 0.297003\n",
      "[158]\ttraining's binary_logloss: 0.296387\n",
      "[159]\ttraining's binary_logloss: 0.295969\n",
      "[160]\ttraining's binary_logloss: 0.295639\n",
      "[161]\ttraining's binary_logloss: 0.29519\n",
      "[162]\ttraining's binary_logloss: 0.294608\n",
      "[163]\ttraining's binary_logloss: 0.29404\n",
      "[164]\ttraining's binary_logloss: 0.293476\n",
      "[165]\ttraining's binary_logloss: 0.293069\n",
      "[166]\ttraining's binary_logloss: 0.292574\n",
      "[167]\ttraining's binary_logloss: 0.292372\n",
      "[168]\ttraining's binary_logloss: 0.291889\n",
      "[169]\ttraining's binary_logloss: 0.291413\n",
      "[170]\ttraining's binary_logloss: 0.291034\n",
      "[171]\ttraining's binary_logloss: 0.290249\n",
      "[172]\ttraining's binary_logloss: 0.289479\n",
      "[173]\ttraining's binary_logloss: 0.288844\n",
      "[174]\ttraining's binary_logloss: 0.288093\n",
      "[175]\ttraining's binary_logloss: 0.287356\n",
      "[176]\ttraining's binary_logloss: 0.286546\n",
      "[177]\ttraining's binary_logloss: 0.285752\n",
      "[178]\ttraining's binary_logloss: 0.284974\n",
      "[179]\ttraining's binary_logloss: 0.284392\n",
      "[180]\ttraining's binary_logloss: 0.283621\n",
      "[181]\ttraining's binary_logloss: 0.283161\n",
      "[182]\ttraining's binary_logloss: 0.282778\n",
      "[183]\ttraining's binary_logloss: 0.28233\n",
      "[184]\ttraining's binary_logloss: 0.281882\n",
      "[185]\ttraining's binary_logloss: 0.28152\n",
      "[186]\ttraining's binary_logloss: 0.280975\n",
      "[187]\ttraining's binary_logloss: 0.280384\n",
      "[188]\ttraining's binary_logloss: 0.279803\n",
      "[189]\ttraining's binary_logloss: 0.279273\n",
      "[190]\ttraining's binary_logloss: 0.278704\n",
      "[191]\ttraining's binary_logloss: 0.278261\n",
      "[192]\ttraining's binary_logloss: 0.277792\n",
      "[193]\ttraining's binary_logloss: 0.277343\n",
      "[194]\ttraining's binary_logloss: 0.2769\n",
      "[195]\ttraining's binary_logloss: 0.276442\n",
      "[196]\ttraining's binary_logloss: 0.276025\n",
      "[197]\ttraining's binary_logloss: 0.275597\n",
      "[198]\ttraining's binary_logloss: 0.275197\n",
      "[199]\ttraining's binary_logloss: 0.274786\n",
      "[200]\ttraining's binary_logloss: 0.274373\n",
      "[201]\ttraining's binary_logloss: 0.273848\n",
      "[202]\ttraining's binary_logloss: 0.273346\n",
      "[203]\ttraining's binary_logloss: 0.272842\n",
      "[204]\ttraining's binary_logloss: 0.272349\n",
      "[205]\ttraining's binary_logloss: 0.271868\n",
      "[206]\ttraining's binary_logloss: 0.271437\n",
      "[207]\ttraining's binary_logloss: 0.271016\n",
      "[208]\ttraining's binary_logloss: 0.270605\n",
      "[209]\ttraining's binary_logloss: 0.270205\n",
      "[210]\ttraining's binary_logloss: 0.269899\n",
      "[211]\ttraining's binary_logloss: 0.269497\n",
      "[212]\ttraining's binary_logloss: 0.269123\n",
      "[213]\ttraining's binary_logloss: 0.268747\n",
      "[214]\ttraining's binary_logloss: 0.268322\n",
      "[215]\ttraining's binary_logloss: 0.267941\n",
      "[216]\ttraining's binary_logloss: 0.267504\n",
      "[217]\ttraining's binary_logloss: 0.267081\n",
      "[218]\ttraining's binary_logloss: 0.266669\n",
      "[219]\ttraining's binary_logloss: 0.266293\n",
      "[220]\ttraining's binary_logloss: 0.265979\n",
      "[221]\ttraining's binary_logloss: 0.265426\n",
      "[222]\ttraining's binary_logloss: 0.264883\n",
      "[223]\ttraining's binary_logloss: 0.264351\n",
      "[224]\ttraining's binary_logloss: 0.263877\n",
      "[225]\ttraining's binary_logloss: 0.263273\n",
      "[226]\ttraining's binary_logloss: 0.262867\n",
      "[227]\ttraining's binary_logloss: 0.262471\n",
      "[228]\ttraining's binary_logloss: 0.262023\n",
      "[229]\ttraining's binary_logloss: 0.261605\n",
      "[230]\ttraining's binary_logloss: 0.261105\n",
      "[231]\ttraining's binary_logloss: 0.260665\n",
      "[232]\ttraining's binary_logloss: 0.260235\n",
      "[233]\ttraining's binary_logloss: 0.259814\n",
      "[234]\ttraining's binary_logloss: 0.259403\n",
      "[235]\ttraining's binary_logloss: 0.259031\n",
      "[236]\ttraining's binary_logloss: 0.258696\n",
      "[237]\ttraining's binary_logloss: 0.25835\n",
      "[238]\ttraining's binary_logloss: 0.258013\n",
      "[239]\ttraining's binary_logloss: 0.257695\n",
      "[240]\ttraining's binary_logloss: 0.257386\n",
      "[241]\ttraining's binary_logloss: 0.25695\n",
      "[242]\ttraining's binary_logloss: 0.256523\n",
      "[243]\ttraining's binary_logloss: 0.25604\n",
      "[244]\ttraining's binary_logloss: 0.255624\n",
      "[245]\ttraining's binary_logloss: 0.255152\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[246]\ttraining's binary_logloss: 0.254907\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[247]\ttraining's binary_logloss: 0.25467\n",
      "[248]\ttraining's binary_logloss: 0.254257\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[249]\ttraining's binary_logloss: 0.254027\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[250]\ttraining's binary_logloss: 0.253803\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[251]\ttraining's binary_logloss: 0.25353\n",
      "[252]\ttraining's binary_logloss: 0.253113\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[253]\ttraining's binary_logloss: 0.252847\n",
      "[254]\ttraining's binary_logloss: 0.252438\n",
      "[255]\ttraining's binary_logloss: 0.251973\n",
      "[256]\ttraining's binary_logloss: 0.251725\n",
      "[257]\ttraining's binary_logloss: 0.251379\n",
      "[258]\ttraining's binary_logloss: 0.251055\n",
      "[259]\ttraining's binary_logloss: 0.250723\n",
      "[260]\ttraining's binary_logloss: 0.250413\n",
      "[261]\ttraining's binary_logloss: 0.249857\n",
      "[262]\ttraining's binary_logloss: 0.24948\n",
      "[263]\ttraining's binary_logloss: 0.249181\n",
      "[264]\ttraining's binary_logloss: 0.24889\n",
      "[265]\ttraining's binary_logloss: 0.24851\n",
      "[266]\ttraining's binary_logloss: 0.248191\n",
      "[267]\ttraining's binary_logloss: 0.247879\n",
      "[268]\ttraining's binary_logloss: 0.247572\n",
      "[269]\ttraining's binary_logloss: 0.247272\n",
      "[270]\ttraining's binary_logloss: 0.246977\n",
      "[271]\ttraining's binary_logloss: 0.24658\n",
      "[272]\ttraining's binary_logloss: 0.24619\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[273]\ttraining's binary_logloss: 0.245963\n",
      "[274]\ttraining's binary_logloss: 0.24558\n",
      "[275]\ttraining's binary_logloss: 0.245199\n",
      "[276]\ttraining's binary_logloss: 0.244722\n",
      "[277]\ttraining's binary_logloss: 0.244293\n",
      "[278]\ttraining's binary_logloss: 0.243832\n",
      "[279]\ttraining's binary_logloss: 0.243381\n",
      "[280]\ttraining's binary_logloss: 0.24294\n",
      "[281]\ttraining's binary_logloss: 0.242177\n",
      "[282]\ttraining's binary_logloss: 0.241406\n",
      "[283]\ttraining's binary_logloss: 0.240647\n",
      "[284]\ttraining's binary_logloss: 0.239918\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[285]\ttraining's binary_logloss: 0.239422\n",
      "[286]\ttraining's binary_logloss: 0.238992\n",
      "[287]\ttraining's binary_logloss: 0.238571\n",
      "[288]\ttraining's binary_logloss: 0.238157\n",
      "[289]\ttraining's binary_logloss: 0.237746\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[290]\ttraining's binary_logloss: 0.237569\n",
      "[291]\ttraining's binary_logloss: 0.237224\n",
      "[292]\ttraining's binary_logloss: 0.236691\n",
      "[293]\ttraining's binary_logloss: 0.236356\n",
      "[294]\ttraining's binary_logloss: 0.236029\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[295]\ttraining's binary_logloss: 0.235785\n",
      "[296]\ttraining's binary_logloss: 0.235385\n",
      "[297]\ttraining's binary_logloss: 0.234952\n",
      "[298]\ttraining's binary_logloss: 0.234562\n",
      "[299]\ttraining's binary_logloss: 0.234121\n",
      "[300]\ttraining's binary_logloss: 0.233745\n",
      "[301]\ttraining's binary_logloss: 0.233361\n",
      "[302]\ttraining's binary_logloss: 0.232939\n",
      "[303]\ttraining's binary_logloss: 0.232526\n",
      "[304]\ttraining's binary_logloss: 0.232186\n",
      "[305]\ttraining's binary_logloss: 0.231783\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[306]\ttraining's binary_logloss: 0.231379\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[307]\ttraining's binary_logloss: 0.230983\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[308]\ttraining's binary_logloss: 0.230593\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[309]\ttraining's binary_logloss: 0.230208\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[310]\ttraining's binary_logloss: 0.229827\n",
      "[311]\ttraining's binary_logloss: 0.229439\n",
      "[312]\ttraining's binary_logloss: 0.229059\n",
      "[313]\ttraining's binary_logloss: 0.22874\n",
      "[314]\ttraining's binary_logloss: 0.228366\n",
      "[315]\ttraining's binary_logloss: 0.228007\n",
      "[316]\ttraining's binary_logloss: 0.227673\n",
      "[317]\ttraining's binary_logloss: 0.227345\n",
      "[318]\ttraining's binary_logloss: 0.226969\n",
      "[319]\ttraining's binary_logloss: 0.226648\n",
      "[320]\ttraining's binary_logloss: 0.226155\n",
      "[321]\ttraining's binary_logloss: 0.225825\n",
      "[322]\ttraining's binary_logloss: 0.22549\n",
      "[323]\ttraining's binary_logloss: 0.225173\n",
      "[324]\ttraining's binary_logloss: 0.224864\n",
      "[325]\ttraining's binary_logloss: 0.224563\n",
      "[326]\ttraining's binary_logloss: 0.224158\n",
      "[327]\ttraining's binary_logloss: 0.223762\n",
      "[328]\ttraining's binary_logloss: 0.223375\n",
      "[329]\ttraining's binary_logloss: 0.222997\n",
      "[330]\ttraining's binary_logloss: 0.222627\n",
      "[331]\ttraining's binary_logloss: 0.222225\n",
      "[332]\ttraining's binary_logloss: 0.221869\n",
      "[333]\ttraining's binary_logloss: 0.221477\n",
      "[334]\ttraining's binary_logloss: 0.221058\n",
      "[335]\ttraining's binary_logloss: 0.220711\n",
      "[336]\ttraining's binary_logloss: 0.220438\n",
      "[337]\ttraining's binary_logloss: 0.220184\n",
      "[338]\ttraining's binary_logloss: 0.219922\n",
      "[339]\ttraining's binary_logloss: 0.219667\n",
      "[340]\ttraining's binary_logloss: 0.219443\n",
      "[341]\ttraining's binary_logloss: 0.219126\n",
      "[342]\ttraining's binary_logloss: 0.218822\n",
      "[343]\ttraining's binary_logloss: 0.218502\n",
      "[344]\ttraining's binary_logloss: 0.218209\n",
      "[345]\ttraining's binary_logloss: 0.217923\n",
      "[346]\ttraining's binary_logloss: 0.217447\n",
      "[347]\ttraining's binary_logloss: 0.21698\n",
      "[348]\ttraining's binary_logloss: 0.216688\n",
      "[349]\ttraining's binary_logloss: 0.216233\n",
      "[350]\ttraining's binary_logloss: 0.215947\n",
      "[351]\ttraining's binary_logloss: 0.215644\n",
      "[352]\ttraining's binary_logloss: 0.215347\n",
      "[353]\ttraining's binary_logloss: 0.215058\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[354]\ttraining's binary_logloss: 0.214834\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[355]\ttraining's binary_logloss: 0.214615\n",
      "[356]\ttraining's binary_logloss: 0.214159\n",
      "[357]\ttraining's binary_logloss: 0.213714\n",
      "[358]\ttraining's binary_logloss: 0.213411\n",
      "[359]\ttraining's binary_logloss: 0.212976\n",
      "[360]\ttraining's binary_logloss: 0.212682\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[361]\ttraining's binary_logloss: 0.212515\n",
      "[362]\ttraining's binary_logloss: 0.212261\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[363]\ttraining's binary_logloss: 0.212172\n",
      "[364]\ttraining's binary_logloss: 0.211929\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[365]\ttraining's binary_logloss: 0.211768\n",
      "[366]\ttraining's binary_logloss: 0.21145\n",
      "[367]\ttraining's binary_logloss: 0.211138\n",
      "[368]\ttraining's binary_logloss: 0.210832\n",
      "[369]\ttraining's binary_logloss: 0.210531\n",
      "[370]\ttraining's binary_logloss: 0.21021\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[371]\ttraining's binary_logloss: 0.209905\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[372]\ttraining's binary_logloss: 0.209654\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[373]\ttraining's binary_logloss: 0.209357\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[374]\ttraining's binary_logloss: 0.209112\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[375]\ttraining's binary_logloss: 0.208823\n",
      "[376]\ttraining's binary_logloss: 0.208448\n",
      "[377]\ttraining's binary_logloss: 0.20808\n",
      "[378]\ttraining's binary_logloss: 0.20773\n",
      "[379]\ttraining's binary_logloss: 0.207382\n",
      "[380]\ttraining's binary_logloss: 0.207014\n",
      "[381]\ttraining's binary_logloss: 0.206676\n",
      "[382]\ttraining's binary_logloss: 0.206346\n",
      "[383]\ttraining's binary_logloss: 0.206053\n",
      "[384]\ttraining's binary_logloss: 0.205541\n",
      "[385]\ttraining's binary_logloss: 0.205213\n",
      "[386]\ttraining's binary_logloss: 0.204837\n",
      "[387]\ttraining's binary_logloss: 0.204502\n",
      "[388]\ttraining's binary_logloss: 0.204174\n",
      "[389]\ttraining's binary_logloss: 0.20385\n",
      "[390]\ttraining's binary_logloss: 0.203531\n",
      "[391]\ttraining's binary_logloss: 0.203107\n",
      "[392]\ttraining's binary_logloss: 0.202641\n",
      "[393]\ttraining's binary_logloss: 0.202184\n",
      "[394]\ttraining's binary_logloss: 0.201737\n",
      "[395]\ttraining's binary_logloss: 0.201414\n",
      "[396]\ttraining's binary_logloss: 0.201016\n",
      "[397]\ttraining's binary_logloss: 0.200625\n",
      "[398]\ttraining's binary_logloss: 0.200247\n",
      "[399]\ttraining's binary_logloss: 0.199888\n",
      "[400]\ttraining's binary_logloss: 0.199509\n",
      "[401]\ttraining's binary_logloss: 0.199316\n",
      "[402]\ttraining's binary_logloss: 0.199126\n",
      "[403]\ttraining's binary_logloss: 0.19894\n",
      "[404]\ttraining's binary_logloss: 0.198757\n",
      "[405]\ttraining's binary_logloss: 0.198579\n",
      "[406]\ttraining's binary_logloss: 0.198272\n",
      "[407]\ttraining's binary_logloss: 0.197933\n",
      "[408]\ttraining's binary_logloss: 0.197588\n",
      "[409]\ttraining's binary_logloss: 0.19724\n",
      "[410]\ttraining's binary_logloss: 0.196916\n",
      "[411]\ttraining's binary_logloss: 0.196553\n",
      "[412]\ttraining's binary_logloss: 0.196232\n",
      "[413]\ttraining's binary_logloss: 0.195879\n",
      "[414]\ttraining's binary_logloss: 0.195611\n",
      "[415]\ttraining's binary_logloss: 0.195266\n",
      "[416]\ttraining's binary_logloss: 0.194843\n",
      "[417]\ttraining's binary_logloss: 0.194425\n",
      "[418]\ttraining's binary_logloss: 0.194009\n",
      "[419]\ttraining's binary_logloss: 0.193604\n",
      "[420]\ttraining's binary_logloss: 0.193203\n",
      "[421]\ttraining's binary_logloss: 0.192855\n",
      "[422]\ttraining's binary_logloss: 0.192569\n",
      "[423]\ttraining's binary_logloss: 0.19223\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[424]\ttraining's binary_logloss: 0.1921\n",
      "[425]\ttraining's binary_logloss: 0.191766\n",
      "[426]\ttraining's binary_logloss: 0.191414\n",
      "[427]\ttraining's binary_logloss: 0.191034\n",
      "[428]\ttraining's binary_logloss: 0.190679\n",
      "[429]\ttraining's binary_logloss: 0.190313\n",
      "[430]\ttraining's binary_logloss: 0.18997\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[431]\ttraining's binary_logloss: 0.189768\n",
      "[432]\ttraining's binary_logloss: 0.189486\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[433]\ttraining's binary_logloss: 0.189289\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[434]\ttraining's binary_logloss: 0.189096\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[435]\ttraining's binary_logloss: 0.188932\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[436]\ttraining's binary_logloss: 0.188708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[437]\ttraining's binary_logloss: 0.18848\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[438]\ttraining's binary_logloss: 0.188257\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[439]\ttraining's binary_logloss: 0.188039\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[440]\ttraining's binary_logloss: 0.187826\n",
      "[441]\ttraining's binary_logloss: 0.187404\n",
      "[442]\ttraining's binary_logloss: 0.186985\n",
      "[443]\ttraining's binary_logloss: 0.186572\n",
      "[444]\ttraining's binary_logloss: 0.186132\n",
      "[445]\ttraining's binary_logloss: 0.185728\n",
      "[446]\ttraining's binary_logloss: 0.185414\n",
      "[447]\ttraining's binary_logloss: 0.185106\n",
      "[448]\ttraining's binary_logloss: 0.184804\n",
      "[449]\ttraining's binary_logloss: 0.184522\n",
      "[450]\ttraining's binary_logloss: 0.184246\n",
      "[451]\ttraining's binary_logloss: 0.183946\n",
      "[452]\ttraining's binary_logloss: 0.183653\n",
      "[453]\ttraining's binary_logloss: 0.183372\n",
      "[454]\ttraining's binary_logloss: 0.183099\n",
      "[455]\ttraining's binary_logloss: 0.182853\n",
      "[456]\ttraining's binary_logloss: 0.182624\n",
      "[457]\ttraining's binary_logloss: 0.182401\n",
      "[458]\ttraining's binary_logloss: 0.182097\n",
      "[459]\ttraining's binary_logloss: 0.181878\n",
      "[460]\ttraining's binary_logloss: 0.181582\n",
      "[461]\ttraining's binary_logloss: 0.181251\n",
      "[462]\ttraining's binary_logloss: 0.18095\n",
      "[463]\ttraining's binary_logloss: 0.180631\n",
      "[464]\ttraining's binary_logloss: 0.180341\n",
      "[465]\ttraining's binary_logloss: 0.180034\n",
      "[466]\ttraining's binary_logloss: 0.179689\n",
      "[467]\ttraining's binary_logloss: 0.179454\n",
      "[468]\ttraining's binary_logloss: 0.179118\n",
      "[469]\ttraining's binary_logloss: 0.178788\n",
      "[470]\ttraining's binary_logloss: 0.178466\n",
      "[471]\ttraining's binary_logloss: 0.178107\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[472]\ttraining's binary_logloss: 0.17786\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[473]\ttraining's binary_logloss: 0.177619\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[474]\ttraining's binary_logloss: 0.177382\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[475]\ttraining's binary_logloss: 0.17715\n",
      "[476]\ttraining's binary_logloss: 0.176808\n",
      "[477]\ttraining's binary_logloss: 0.17646\n",
      "[478]\ttraining's binary_logloss: 0.176118\n",
      "[479]\ttraining's binary_logloss: 0.175786\n",
      "[480]\ttraining's binary_logloss: 0.175455\n",
      "[481]\ttraining's binary_logloss: 0.175141\n",
      "[482]\ttraining's binary_logloss: 0.17483\n",
      "[483]\ttraining's binary_logloss: 0.174526\n",
      "[484]\ttraining's binary_logloss: 0.174224\n",
      "[485]\ttraining's binary_logloss: 0.17393\n",
      "[486]\ttraining's binary_logloss: 0.173622\n",
      "[487]\ttraining's binary_logloss: 0.173394\n",
      "[488]\ttraining's binary_logloss: 0.173096\n",
      "[489]\ttraining's binary_logloss: 0.172862\n",
      "[490]\ttraining's binary_logloss: 0.172633\n",
      "[491]\ttraining's binary_logloss: 0.172382\n",
      "[492]\ttraining's binary_logloss: 0.172115\n",
      "[493]\ttraining's binary_logloss: 0.171855\n",
      "[494]\ttraining's binary_logloss: 0.171614\n",
      "[495]\ttraining's binary_logloss: 0.17138\n",
      "[496]\ttraining's binary_logloss: 0.171078\n",
      "[497]\ttraining's binary_logloss: 0.170825\n",
      "[498]\ttraining's binary_logloss: 0.170644\n",
      "[499]\ttraining's binary_logloss: 0.170353\n",
      "[500]\ttraining's binary_logloss: 0.170179\n",
      "[501]\ttraining's binary_logloss: 0.169844\n",
      "[502]\ttraining's binary_logloss: 0.169501\n",
      "[503]\ttraining's binary_logloss: 0.169263\n",
      "[504]\ttraining's binary_logloss: 0.169029\n",
      "[505]\ttraining's binary_logloss: 0.168656\n",
      "[506]\ttraining's binary_logloss: 0.16837\n",
      "[507]\ttraining's binary_logloss: 0.168091\n",
      "[508]\ttraining's binary_logloss: 0.167817\n",
      "[509]\ttraining's binary_logloss: 0.16754\n",
      "[510]\ttraining's binary_logloss: 0.167277\n",
      "[511]\ttraining's binary_logloss: 0.166995\n",
      "[512]\ttraining's binary_logloss: 0.166718\n",
      "[513]\ttraining's binary_logloss: 0.166447\n",
      "[514]\ttraining's binary_logloss: 0.166301\n",
      "[515]\ttraining's binary_logloss: 0.166087\n",
      "[516]\ttraining's binary_logloss: 0.165783\n",
      "[517]\ttraining's binary_logloss: 0.165529\n",
      "[518]\ttraining's binary_logloss: 0.165231\n",
      "[519]\ttraining's binary_logloss: 0.164998\n",
      "[520]\ttraining's binary_logloss: 0.16477\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[521]\ttraining's binary_logloss: 0.164593\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[522]\ttraining's binary_logloss: 0.16442\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[523]\ttraining's binary_logloss: 0.164249\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[524]\ttraining's binary_logloss: 0.164082\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[525]\ttraining's binary_logloss: 0.163918\n",
      "[526]\ttraining's binary_logloss: 0.163679\n",
      "[527]\ttraining's binary_logloss: 0.163446\n",
      "[528]\ttraining's binary_logloss: 0.163251\n",
      "[529]\ttraining's binary_logloss: 0.163024\n",
      "[530]\ttraining's binary_logloss: 0.162801\n",
      "[531]\ttraining's binary_logloss: 0.162538\n",
      "[532]\ttraining's binary_logloss: 0.162284\n",
      "[533]\ttraining's binary_logloss: 0.162031\n",
      "[534]\ttraining's binary_logloss: 0.161787\n",
      "[535]\ttraining's binary_logloss: 0.161545\n",
      "[536]\ttraining's binary_logloss: 0.161275\n",
      "[537]\ttraining's binary_logloss: 0.160957\n",
      "[538]\ttraining's binary_logloss: 0.160645\n",
      "[539]\ttraining's binary_logloss: 0.160339\n",
      "[540]\ttraining's binary_logloss: 0.160079\n",
      "[541]\ttraining's binary_logloss: 0.159883\n",
      "[542]\ttraining's binary_logloss: 0.159654\n",
      "[543]\ttraining's binary_logloss: 0.159431\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[544]\ttraining's binary_logloss: 0.15937\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[545]\ttraining's binary_logloss: 0.159311\n",
      "[546]\ttraining's binary_logloss: 0.159129\n",
      "[547]\ttraining's binary_logloss: 0.158891\n",
      "[548]\ttraining's binary_logloss: 0.158658\n",
      "[549]\ttraining's binary_logloss: 0.158441\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[550]\ttraining's binary_logloss: 0.158299\n",
      "[551]\ttraining's binary_logloss: 0.158091\n",
      "[552]\ttraining's binary_logloss: 0.157826\n",
      "[553]\ttraining's binary_logloss: 0.157582\n",
      "[554]\ttraining's binary_logloss: 0.157379\n",
      "[555]\ttraining's binary_logloss: 0.15718\n",
      "[556]\ttraining's binary_logloss: 0.156969\n",
      "[557]\ttraining's binary_logloss: 0.156777\n",
      "[558]\ttraining's binary_logloss: 0.156456\n",
      "[559]\ttraining's binary_logloss: 0.156141\n",
      "[560]\ttraining's binary_logloss: 0.155942\n",
      "[561]\ttraining's binary_logloss: 0.155759\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[562]\ttraining's binary_logloss: 0.155649\n",
      "[563]\ttraining's binary_logloss: 0.155472\n",
      "[564]\ttraining's binary_logloss: 0.155275\n",
      "[565]\ttraining's binary_logloss: 0.155104\n",
      "[566]\ttraining's binary_logloss: 0.154846\n",
      "[567]\ttraining's binary_logloss: 0.154594\n",
      "[568]\ttraining's binary_logloss: 0.154346\n",
      "[569]\ttraining's binary_logloss: 0.154126\n",
      "[570]\ttraining's binary_logloss: 0.153819\n",
      "[571]\ttraining's binary_logloss: 0.153538\n",
      "[572]\ttraining's binary_logloss: 0.153262\n",
      "[573]\ttraining's binary_logloss: 0.152821\n",
      "[574]\ttraining's binary_logloss: 0.152406\n",
      "[575]\ttraining's binary_logloss: 0.152136\n",
      "[576]\ttraining's binary_logloss: 0.151942\n",
      "[577]\ttraining's binary_logloss: 0.151729\n",
      "[578]\ttraining's binary_logloss: 0.151538\n",
      "[579]\ttraining's binary_logloss: 0.15135\n",
      "[580]\ttraining's binary_logloss: 0.151166\n",
      "[581]\ttraining's binary_logloss: 0.15083\n",
      "[582]\ttraining's binary_logloss: 0.150511\n",
      "[583]\ttraining's binary_logloss: 0.150187\n",
      "[584]\ttraining's binary_logloss: 0.149869\n",
      "[585]\ttraining's binary_logloss: 0.149557\n",
      "[586]\ttraining's binary_logloss: 0.149325\n",
      "[587]\ttraining's binary_logloss: 0.149143\n",
      "[588]\ttraining's binary_logloss: 0.148919\n",
      "[589]\ttraining's binary_logloss: 0.148696\n",
      "[590]\ttraining's binary_logloss: 0.148478\n",
      "[591]\ttraining's binary_logloss: 0.148292\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[592]\ttraining's binary_logloss: 0.148191\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[593]\ttraining's binary_logloss: 0.148089\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[594]\ttraining's binary_logloss: 0.147991\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[595]\ttraining's binary_logloss: 0.147895\n",
      "[596]\ttraining's binary_logloss: 0.147637\n",
      "[597]\ttraining's binary_logloss: 0.147383\n",
      "[598]\ttraining's binary_logloss: 0.147107\n",
      "[599]\ttraining's binary_logloss: 0.146868\n",
      "[600]\ttraining's binary_logloss: 0.146615\n",
      "[601]\ttraining's binary_logloss: 0.146352\n",
      "[602]\ttraining's binary_logloss: 0.146096\n",
      "[603]\ttraining's binary_logloss: 0.145845\n",
      "[604]\ttraining's binary_logloss: 0.145599\n",
      "[605]\ttraining's binary_logloss: 0.145357\n",
      "[606]\ttraining's binary_logloss: 0.145131\n",
      "[607]\ttraining's binary_logloss: 0.14493\n",
      "[608]\ttraining's binary_logloss: 0.144707\n",
      "[609]\ttraining's binary_logloss: 0.14449\n",
      "[610]\ttraining's binary_logloss: 0.144295\n",
      "[611]\ttraining's binary_logloss: 0.144082\n",
      "[612]\ttraining's binary_logloss: 0.143875\n",
      "[613]\ttraining's binary_logloss: 0.143672\n",
      "[614]\ttraining's binary_logloss: 0.143518\n",
      "[615]\ttraining's binary_logloss: 0.14332\n",
      "[616]\ttraining's binary_logloss: 0.143095\n",
      "[617]\ttraining's binary_logloss: 0.142875\n",
      "[618]\ttraining's binary_logloss: 0.142649\n",
      "[619]\ttraining's binary_logloss: 0.142569\n",
      "[620]\ttraining's binary_logloss: 0.142493\n",
      "[621]\ttraining's binary_logloss: 0.142308\n",
      "[622]\ttraining's binary_logloss: 0.142127\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[623]\ttraining's binary_logloss: 0.14202\n",
      "[624]\ttraining's binary_logloss: 0.141841\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[625]\ttraining's binary_logloss: 0.141735\n",
      "[626]\ttraining's binary_logloss: 0.141477\n",
      "[627]\ttraining's binary_logloss: 0.141224\n",
      "[628]\ttraining's binary_logloss: 0.14097\n",
      "[629]\ttraining's binary_logloss: 0.14072\n",
      "[630]\ttraining's binary_logloss: 0.140479\n",
      "[631]\ttraining's binary_logloss: 0.14022\n",
      "[632]\ttraining's binary_logloss: 0.139965\n",
      "[633]\ttraining's binary_logloss: 0.139715\n",
      "[634]\ttraining's binary_logloss: 0.139532\n",
      "[635]\ttraining's binary_logloss: 0.13939\n",
      "[636]\ttraining's binary_logloss: 0.13914\n",
      "[637]\ttraining's binary_logloss: 0.138895\n",
      "[638]\ttraining's binary_logloss: 0.138641\n",
      "[639]\ttraining's binary_logloss: 0.138392\n",
      "[640]\ttraining's binary_logloss: 0.138158\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[641]\ttraining's binary_logloss: 0.137973\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[642]\ttraining's binary_logloss: 0.137792\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[643]\ttraining's binary_logloss: 0.137617\n",
      "[644]\ttraining's binary_logloss: 0.137488\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[645]\ttraining's binary_logloss: 0.137311\n",
      "[646]\ttraining's binary_logloss: 0.137051\n",
      "[647]\ttraining's binary_logloss: 0.13677\n",
      "[648]\ttraining's binary_logloss: 0.136486\n",
      "[649]\ttraining's binary_logloss: 0.136212\n",
      "[650]\ttraining's binary_logloss: 0.135942\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[651]\ttraining's binary_logloss: 0.135772\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[652]\ttraining's binary_logloss: 0.135606\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[653]\ttraining's binary_logloss: 0.135443\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[654]\ttraining's binary_logloss: 0.135283\n",
      "[655]\ttraining's binary_logloss: 0.135074\n",
      "[656]\ttraining's binary_logloss: 0.134773\n",
      "[657]\ttraining's binary_logloss: 0.134478\n",
      "[658]\ttraining's binary_logloss: 0.134188\n",
      "[659]\ttraining's binary_logloss: 0.133903\n",
      "[660]\ttraining's binary_logloss: 0.133624\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[661]\ttraining's binary_logloss: 0.133438\n",
      "[662]\ttraining's binary_logloss: 0.1333\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[663]\ttraining's binary_logloss: 0.133117\n",
      "[664]\ttraining's binary_logloss: 0.132978\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[665]\ttraining's binary_logloss: 0.132798\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[666]\ttraining's binary_logloss: 0.132655\n",
      "[667]\ttraining's binary_logloss: 0.132507\n",
      "[668]\ttraining's binary_logloss: 0.132361\n",
      "[669]\ttraining's binary_logloss: 0.132219\n",
      "[670]\ttraining's binary_logloss: 0.131932\n",
      "[671]\ttraining's binary_logloss: 0.131626\n",
      "[672]\ttraining's binary_logloss: 0.13139\n",
      "[673]\ttraining's binary_logloss: 0.131108\n",
      "[674]\ttraining's binary_logloss: 0.130812\n",
      "[675]\ttraining's binary_logloss: 0.130539\n",
      "[676]\ttraining's binary_logloss: 0.130286\n",
      "[677]\ttraining's binary_logloss: 0.130037\n",
      "[678]\ttraining's binary_logloss: 0.129831\n",
      "[679]\ttraining's binary_logloss: 0.129625\n",
      "[680]\ttraining's binary_logloss: 0.129426\n",
      "[681]\ttraining's binary_logloss: 0.129273\n",
      "[682]\ttraining's binary_logloss: 0.12913\n",
      "[683]\ttraining's binary_logloss: 0.128983\n",
      "[684]\ttraining's binary_logloss: 0.128829\n",
      "[685]\ttraining's binary_logloss: 0.128688\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[686]\ttraining's binary_logloss: 0.128495\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[687]\ttraining's binary_logloss: 0.128305\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[688]\ttraining's binary_logloss: 0.128119\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[689]\ttraining's binary_logloss: 0.127935\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[690]\ttraining's binary_logloss: 0.127741\n",
      "[691]\ttraining's binary_logloss: 0.127488\n",
      "[692]\ttraining's binary_logloss: 0.127241\n",
      "[693]\ttraining's binary_logloss: 0.127017\n",
      "[694]\ttraining's binary_logloss: 0.126774\n",
      "[695]\ttraining's binary_logloss: 0.126557\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[696]\ttraining's binary_logloss: 0.126356\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[697]\ttraining's binary_logloss: 0.12616\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[698]\ttraining's binary_logloss: 0.125967\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[699]\ttraining's binary_logloss: 0.125777\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[700]\ttraining's binary_logloss: 0.125576\n",
      "[701]\ttraining's binary_logloss: 0.125321\n",
      "[702]\ttraining's binary_logloss: 0.125083\n",
      "[703]\ttraining's binary_logloss: 0.124849\n",
      "[704]\ttraining's binary_logloss: 0.12462\n",
      "[705]\ttraining's binary_logloss: 0.124395\n",
      "[706]\ttraining's binary_logloss: 0.124281\n",
      "[707]\ttraining's binary_logloss: 0.124167\n",
      "[708]\ttraining's binary_logloss: 0.124055\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[709]\ttraining's binary_logloss: 0.124011\n",
      "[710]\ttraining's binary_logloss: 0.1239\n",
      "[711]\ttraining's binary_logloss: 0.123768\n",
      "[712]\ttraining's binary_logloss: 0.123639\n",
      "[713]\ttraining's binary_logloss: 0.123513\n",
      "[714]\ttraining's binary_logloss: 0.12339\n",
      "[715]\ttraining's binary_logloss: 0.123249\n",
      "[716]\ttraining's binary_logloss: 0.12314\n",
      "[717]\ttraining's binary_logloss: 0.123033\n",
      "[718]\ttraining's binary_logloss: 0.122929\n",
      "[719]\ttraining's binary_logloss: 0.122788\n",
      "[720]\ttraining's binary_logloss: 0.122686\n",
      "[721]\ttraining's binary_logloss: 0.122536\n",
      "[722]\ttraining's binary_logloss: 0.12239\n",
      "[723]\ttraining's binary_logloss: 0.122247\n",
      "[724]\ttraining's binary_logloss: 0.122082\n",
      "[725]\ttraining's binary_logloss: 0.121943\n",
      "[726]\ttraining's binary_logloss: 0.121614\n",
      "[727]\ttraining's binary_logloss: 0.121287\n",
      "[728]\ttraining's binary_logloss: 0.120964\n",
      "[729]\ttraining's binary_logloss: 0.120647\n",
      "[730]\ttraining's binary_logloss: 0.120335\n",
      "[731]\ttraining's binary_logloss: 0.120203\n",
      "[732]\ttraining's binary_logloss: 0.120106\n",
      "[733]\ttraining's binary_logloss: 0.119987\n",
      "[734]\ttraining's binary_logloss: 0.11986\n",
      "[735]\ttraining's binary_logloss: 0.119739\n",
      "[736]\ttraining's binary_logloss: 0.119544\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[737]\ttraining's binary_logloss: 0.119445\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[738]\ttraining's binary_logloss: 0.119287\n",
      "[739]\ttraining's binary_logloss: 0.11908\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[740]\ttraining's binary_logloss: 0.118971\n",
      "[741]\ttraining's binary_logloss: 0.118796\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[742]\ttraining's binary_logloss: 0.118667\n",
      "[743]\ttraining's binary_logloss: 0.118514\n",
      "[744]\ttraining's binary_logloss: 0.118345\n",
      "[745]\ttraining's binary_logloss: 0.118179\n",
      "[746]\ttraining's binary_logloss: 0.118052\n",
      "[747]\ttraining's binary_logloss: 0.117924\n",
      "[748]\ttraining's binary_logloss: 0.117834\n",
      "[749]\ttraining's binary_logloss: 0.117713\n",
      "[750]\ttraining's binary_logloss: 0.117595\n",
      "[751]\ttraining's binary_logloss: 0.117399\n",
      "[752]\ttraining's binary_logloss: 0.117184\n",
      "[753]\ttraining's binary_logloss: 0.116974\n",
      "[754]\ttraining's binary_logloss: 0.116769\n",
      "[755]\ttraining's binary_logloss: 0.116568\n",
      "[756]\ttraining's binary_logloss: 0.116316\n",
      "[757]\ttraining's binary_logloss: 0.11608\n",
      "[758]\ttraining's binary_logloss: 0.115836\n",
      "[759]\ttraining's binary_logloss: 0.115607\n",
      "[760]\ttraining's binary_logloss: 0.115363\n",
      "[761]\ttraining's binary_logloss: 0.115168\n",
      "[762]\ttraining's binary_logloss: 0.114982\n",
      "[763]\ttraining's binary_logloss: 0.114853\n",
      "[764]\ttraining's binary_logloss: 0.114662\n",
      "[765]\ttraining's binary_logloss: 0.114532\n",
      "[766]\ttraining's binary_logloss: 0.114278\n",
      "[767]\ttraining's binary_logloss: 0.114029\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[768]\ttraining's binary_logloss: 0.113939\n",
      "[769]\ttraining's binary_logloss: 0.113698\n",
      "[770]\ttraining's binary_logloss: 0.113457\n",
      "[771]\ttraining's binary_logloss: 0.113274\n",
      "[772]\ttraining's binary_logloss: 0.113094\n",
      "[773]\ttraining's binary_logloss: 0.112901\n",
      "[774]\ttraining's binary_logloss: 0.112721\n",
      "[775]\ttraining's binary_logloss: 0.112548\n",
      "[776]\ttraining's binary_logloss: 0.112372\n",
      "[777]\ttraining's binary_logloss: 0.112182\n",
      "[778]\ttraining's binary_logloss: 0.112028\n",
      "[779]\ttraining's binary_logloss: 0.111843\n",
      "[780]\ttraining's binary_logloss: 0.111678\n",
      "[781]\ttraining's binary_logloss: 0.111508\n",
      "[782]\ttraining's binary_logloss: 0.111342\n",
      "[783]\ttraining's binary_logloss: 0.111177\n",
      "[784]\ttraining's binary_logloss: 0.111016\n",
      "[785]\ttraining's binary_logloss: 0.110858\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[786]\ttraining's binary_logloss: 0.110739\n",
      "[787]\ttraining's binary_logloss: 0.110526\n",
      "[788]\ttraining's binary_logloss: 0.110317\n",
      "[789]\ttraining's binary_logloss: 0.110122\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[790]\ttraining's binary_logloss: 0.110003\n",
      "[791]\ttraining's binary_logloss: 0.109775\n",
      "[792]\ttraining's binary_logloss: 0.10953\n",
      "[793]\ttraining's binary_logloss: 0.10931\n",
      "[794]\ttraining's binary_logloss: 0.109048\n",
      "[795]\ttraining's binary_logloss: 0.108737\n",
      "[796]\ttraining's binary_logloss: 0.108541\n",
      "[797]\ttraining's binary_logloss: 0.108349\n",
      "[798]\ttraining's binary_logloss: 0.108162\n",
      "[799]\ttraining's binary_logloss: 0.107989\n",
      "[800]\ttraining's binary_logloss: 0.107808\n",
      "[801]\ttraining's binary_logloss: 0.107718\n",
      "[802]\ttraining's binary_logloss: 0.10763\n",
      "[803]\ttraining's binary_logloss: 0.107541\n",
      "[804]\ttraining's binary_logloss: 0.107389\n",
      "[805]\ttraining's binary_logloss: 0.107245\n",
      "[806]\ttraining's binary_logloss: 0.107096\n",
      "[807]\ttraining's binary_logloss: 0.106943\n",
      "[808]\ttraining's binary_logloss: 0.106806\n",
      "[809]\ttraining's binary_logloss: 0.106664\n",
      "[810]\ttraining's binary_logloss: 0.10653\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[811]\ttraining's binary_logloss: 0.106433\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[812]\ttraining's binary_logloss: 0.106344\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[813]\ttraining's binary_logloss: 0.106256\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[814]\ttraining's binary_logloss: 0.106162\n",
      "[815]\ttraining's binary_logloss: 0.106046\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[816]\ttraining's binary_logloss: 0.105976\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[817]\ttraining's binary_logloss: 0.105913\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[818]\ttraining's binary_logloss: 0.105851\n",
      "[819]\ttraining's binary_logloss: 0.105695\n",
      "[820]\ttraining's binary_logloss: 0.105543\n",
      "[821]\ttraining's binary_logloss: 0.105436\n",
      "[822]\ttraining's binary_logloss: 0.10533\n",
      "[823]\ttraining's binary_logloss: 0.105234\n",
      "[824]\ttraining's binary_logloss: 0.105139\n",
      "[825]\ttraining's binary_logloss: 0.104995\n",
      "[826]\ttraining's binary_logloss: 0.104796\n",
      "[827]\ttraining's binary_logloss: 0.104601\n",
      "[828]\ttraining's binary_logloss: 0.104411\n",
      "[829]\ttraining's binary_logloss: 0.104254\n",
      "[830]\ttraining's binary_logloss: 0.104067\n",
      "[831]\ttraining's binary_logloss: 0.103878\n",
      "[832]\ttraining's binary_logloss: 0.103708\n",
      "[833]\ttraining's binary_logloss: 0.103525\n",
      "[834]\ttraining's binary_logloss: 0.103346\n",
      "[835]\ttraining's binary_logloss: 0.103207\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[836]\ttraining's binary_logloss: 0.103094\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[837]\ttraining's binary_logloss: 0.102958\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[838]\ttraining's binary_logloss: 0.102847\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[839]\ttraining's binary_logloss: 0.102704\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[840]\ttraining's binary_logloss: 0.102602\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[841]\ttraining's binary_logloss: 0.102486\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[842]\ttraining's binary_logloss: 0.102372\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[843]\ttraining's binary_logloss: 0.10226\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[844]\ttraining's binary_logloss: 0.10215\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[845]\ttraining's binary_logloss: 0.102041\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[846]\ttraining's binary_logloss: 0.101985\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[847]\ttraining's binary_logloss: 0.10193\n",
      "[848]\ttraining's binary_logloss: 0.101851\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[849]\ttraining's binary_logloss: 0.101798\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[850]\ttraining's binary_logloss: 0.101747\n",
      "[851]\ttraining's binary_logloss: 0.101577\n",
      "[852]\ttraining's binary_logloss: 0.101408\n",
      "[853]\ttraining's binary_logloss: 0.101242\n",
      "[854]\ttraining's binary_logloss: 0.101138\n",
      "[855]\ttraining's binary_logloss: 0.101036\n",
      "[856]\ttraining's binary_logloss: 0.100924\n",
      "[857]\ttraining's binary_logloss: 0.100838\n",
      "[858]\ttraining's binary_logloss: 0.100729\n",
      "[859]\ttraining's binary_logloss: 0.100645\n",
      "[860]\ttraining's binary_logloss: 0.10054\n",
      "[861]\ttraining's binary_logloss: 0.100315\n",
      "[862]\ttraining's binary_logloss: 0.100135\n",
      "[863]\ttraining's binary_logloss: 0.0999584\n",
      "[864]\ttraining's binary_logloss: 0.0997845\n",
      "[865]\ttraining's binary_logloss: 0.0996136\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[866]\ttraining's binary_logloss: 0.0995403\n",
      "[867]\ttraining's binary_logloss: 0.0994561\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[868]\ttraining's binary_logloss: 0.0993853\n",
      "[869]\ttraining's binary_logloss: 0.0992971\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[870]\ttraining's binary_logloss: 0.0992287\n",
      "[871]\ttraining's binary_logloss: 0.0991716\n",
      "[872]\ttraining's binary_logloss: 0.0990482\n",
      "[873]\ttraining's binary_logloss: 0.0990051\n",
      "[874]\ttraining's binary_logloss: 0.0989493\n",
      "[875]\ttraining's binary_logloss: 0.0988277\n",
      "[876]\ttraining's binary_logloss: 0.0986497\n",
      "[877]\ttraining's binary_logloss: 0.0984542\n",
      "[878]\ttraining's binary_logloss: 0.0982627\n",
      "[879]\ttraining's binary_logloss: 0.0980749\n",
      "[880]\ttraining's binary_logloss: 0.0978909\n",
      "[881]\ttraining's binary_logloss: 0.0977098\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[882]\ttraining's binary_logloss: 0.0975841\n",
      "[883]\ttraining's binary_logloss: 0.0974406\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[884]\ttraining's binary_logloss: 0.0973178\n",
      "[885]\ttraining's binary_logloss: 0.0971716\n",
      "[886]\ttraining's binary_logloss: 0.0970289\n",
      "[887]\ttraining's binary_logloss: 0.096898\n",
      "[888]\ttraining's binary_logloss: 0.0967641\n",
      "[889]\ttraining's binary_logloss: 0.0966249\n",
      "[890]\ttraining's binary_logloss: 0.0964998\n",
      "[891]\ttraining's binary_logloss: 0.0963519\n",
      "[892]\ttraining's binary_logloss: 0.0962199\n",
      "[893]\ttraining's binary_logloss: 0.0960649\n",
      "[894]\ttraining's binary_logloss: 0.0959014\n",
      "[895]\ttraining's binary_logloss: 0.09576\n",
      "[896]\ttraining's binary_logloss: 0.0956283\n",
      "[897]\ttraining's binary_logloss: 0.0954989\n",
      "[898]\ttraining's binary_logloss: 0.0953718\n",
      "[899]\ttraining's binary_logloss: 0.0952469\n",
      "[900]\ttraining's binary_logloss: 0.0951278\n",
      "[901]\ttraining's binary_logloss: 0.0949474\n",
      "[902]\ttraining's binary_logloss: 0.0947836\n",
      "[903]\ttraining's binary_logloss: 0.0946095\n",
      "[904]\ttraining's binary_logloss: 0.094439\n",
      "[905]\ttraining's binary_logloss: 0.0942719\n",
      "[906]\ttraining's binary_logloss: 0.0940493\n",
      "[907]\ttraining's binary_logloss: 0.0938362\n",
      "[908]\ttraining's binary_logloss: 0.093627\n",
      "[909]\ttraining's binary_logloss: 0.0934217\n",
      "[910]\ttraining's binary_logloss: 0.0932201\n",
      "[911]\ttraining's binary_logloss: 0.0930626\n",
      "[912]\ttraining's binary_logloss: 0.0929079\n",
      "[913]\ttraining's binary_logloss: 0.0927624\n",
      "[914]\ttraining's binary_logloss: 0.0926175\n",
      "[915]\ttraining's binary_logloss: 0.0924673\n",
      "[916]\ttraining's binary_logloss: 0.0923426\n",
      "[917]\ttraining's binary_logloss: 0.0922203\n",
      "[918]\ttraining's binary_logloss: 0.0921002\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[919]\ttraining's binary_logloss: 0.0920076\n",
      "[920]\ttraining's binary_logloss: 0.0918899\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[921]\ttraining's binary_logloss: 0.0918112\n",
      "[922]\ttraining's binary_logloss: 0.0917091\n",
      "[923]\ttraining's binary_logloss: 0.0916092\n",
      "[924]\ttraining's binary_logloss: 0.0915105\n",
      "[925]\ttraining's binary_logloss: 0.0914139\n",
      "[926]\ttraining's binary_logloss: 0.0912699\n",
      "[927]\ttraining's binary_logloss: 0.0911599\n",
      "[928]\ttraining's binary_logloss: 0.091026\n",
      "[929]\ttraining's binary_logloss: 0.0908869\n",
      "[930]\ttraining's binary_logloss: 0.0907527\n",
      "[931]\ttraining's binary_logloss: 0.0906615\n",
      "[932]\ttraining's binary_logloss: 0.090573\n",
      "[933]\ttraining's binary_logloss: 0.0904973\n",
      "[934]\ttraining's binary_logloss: 0.0904237\n",
      "[935]\ttraining's binary_logloss: 0.0903523\n",
      "[936]\ttraining's binary_logloss: 0.0902046\n",
      "[937]\ttraining's binary_logloss: 0.0900885\n",
      "[938]\ttraining's binary_logloss: 0.0899704\n",
      "[939]\ttraining's binary_logloss: 0.0898523\n",
      "[940]\ttraining's binary_logloss: 0.089738\n",
      "[941]\ttraining's binary_logloss: 0.08959\n",
      "[942]\ttraining's binary_logloss: 0.0894448\n",
      "[943]\ttraining's binary_logloss: 0.0893021\n",
      "[944]\ttraining's binary_logloss: 0.0891994\n",
      "[945]\ttraining's binary_logloss: 0.0890602\n",
      "[946]\ttraining's binary_logloss: 0.0888968\n",
      "[947]\ttraining's binary_logloss: 0.0887527\n",
      "[948]\ttraining's binary_logloss: 0.088593\n",
      "[949]\ttraining's binary_logloss: 0.0884364\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[950]\ttraining's binary_logloss: 0.0883627\n",
      "[951]\ttraining's binary_logloss: 0.0882185\n",
      "[952]\ttraining's binary_logloss: 0.0880555\n",
      "[953]\ttraining's binary_logloss: 0.0878951\n",
      "[954]\ttraining's binary_logloss: 0.0877379\n",
      "[955]\ttraining's binary_logloss: 0.087584\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[956]\ttraining's binary_logloss: 0.0875339\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[957]\ttraining's binary_logloss: 0.0874851\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[958]\ttraining's binary_logloss: 0.0874357\n",
      "[959]\ttraining's binary_logloss: 0.0872705\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[960]\ttraining's binary_logloss: 0.08722\n",
      "[961]\ttraining's binary_logloss: 0.0871161\n",
      "[962]\ttraining's binary_logloss: 0.0869999\n",
      "[963]\ttraining's binary_logloss: 0.0868884\n",
      "[964]\ttraining's binary_logloss: 0.0867749\n",
      "[965]\ttraining's binary_logloss: 0.0866661\n",
      "[966]\ttraining's binary_logloss: 0.0865722\n",
      "[967]\ttraining's binary_logloss: 0.0864808\n",
      "[968]\ttraining's binary_logloss: 0.0863759\n",
      "[969]\ttraining's binary_logloss: 0.0862891\n",
      "[970]\ttraining's binary_logloss: 0.0861888\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[971]\ttraining's binary_logloss: 0.0860946\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[972]\ttraining's binary_logloss: 0.0860022\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[973]\ttraining's binary_logloss: 0.0859116\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[974]\ttraining's binary_logloss: 0.0858004\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[975]\ttraining's binary_logloss: 0.0857117\n",
      "[976]\ttraining's binary_logloss: 0.0855992\n",
      "[977]\ttraining's binary_logloss: 0.0854796\n",
      "[978]\ttraining's binary_logloss: 0.0853799\n",
      "[979]\ttraining's binary_logloss: 0.0852839\n",
      "[980]\ttraining's binary_logloss: 0.0851668\n",
      "[981]\ttraining's binary_logloss: 0.0849854\n",
      "[982]\ttraining's binary_logloss: 0.0848093\n",
      "[983]\ttraining's binary_logloss: 0.0846303\n",
      "[984]\ttraining's binary_logloss: 0.0844516\n",
      "[985]\ttraining's binary_logloss: 0.0842971\n",
      "[986]\ttraining's binary_logloss: 0.0840876\n",
      "[987]\ttraining's binary_logloss: 0.0838988\n",
      "[988]\ttraining's binary_logloss: 0.0837028\n",
      "[989]\ttraining's binary_logloss: 0.0835025\n",
      "[990]\ttraining's binary_logloss: 0.0833057\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[991]\ttraining's binary_logloss: 0.0832469\n",
      "[992]\ttraining's binary_logloss: 0.0831599\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[993]\ttraining's binary_logloss: 0.0831028\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[994]\ttraining's binary_logloss: 0.0830471\n",
      "[995]\ttraining's binary_logloss: 0.0829757\n",
      "[996]\ttraining's binary_logloss: 0.082873\n",
      "[997]\ttraining's binary_logloss: 0.0827396\n",
      "[998]\ttraining's binary_logloss: 0.0826089\n",
      "[999]\ttraining's binary_logloss: 0.0824809\n",
      "[1000]\ttraining's binary_logloss: 0.0823546\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.0823546\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.93      0.96       108\n",
      "         1.0       0.65      0.94      0.77        16\n",
      "\n",
      "    accuracy                           0.93       124\n",
      "   macro avg       0.82      0.93      0.86       124\n",
      "weighted avg       0.95      0.93      0.93       124\n",
      "\n",
      "Accuracy: 0.9274193548387096\n",
      "balanced_log_loss is:  2.3585803176128444\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"LGBM Classifier\")\n",
    "\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "# Use warnings.filterwarnings() to ignore specific warning types\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "X = df_norm.drop(['Class'], axis = 1)\n",
    "y = df_norm['Class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n",
    "\n",
    "# Define the hyperparameters for LightGBM\n",
    "params = {\n",
    "    'objective': 'binary',           # For binary classification\n",
    "    'boosting_type': 'gbdt',         # Gradient Boosting Decision Tree\n",
    "    'metric': 'binary_logloss',      # Logarithmic loss for binary classification\n",
    "    'num_leaves': 31,                # Maximum number of leaves in one tree\n",
    "    'learning_rate': 0.01,           # Learning rate for boosting\n",
    "    'feature_fraction': 0.9,         # Percentage of features to consider for each tree\n",
    "    'bagging_fraction': 0.8,         # Percentage of data samples used for bagging\n",
    "    'bagging_freq': 5,  # Frequency for bagging\n",
    "    'bagging_seed': 5,\n",
    "    'verbose': 1,                    # 0: Silent, 1: Print info during training\n",
    "    'early_stopping_rounds': 10,     # Number of rounds without improvement to stop training\n",
    "    'is_unbalance': True,            # Handle class imbalance automatically (reduced 0.91 to 0.85)\n",
    "    'max_depth': 2,                  # Maximum tree depth for base learners, <=0 means no limit.\n",
    "    'min_child_weight':0,            # Minimum sum of instance weight (Hessian) needed in a child (leaf).\n",
    "    'reg_alpha': 0.1,                # L1 regularization term (default is 0)\n",
    "    'reg_lambda': 0.1,               # L2 regularization term (default is 0)\n",
    "}\n",
    "\n",
    "# Create the LightGBM dataset\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "\n",
    "# Train the LightGBM model\n",
    "model_lgb = lgb.train(params, train_data, num_boost_round=1000, valid_sets=[train_data], early_stopping_rounds=10)\n",
    "\n",
    "y_pred=model_lgb.predict(X_test)\n",
    "\n",
    "# Convert probabilities to binary predictions (0 or 1)\n",
    "y_pred_binary = [1.0 if p >= 0.5 else 0.0 for p in y_pred]\n",
    "\n",
    "confusion=confusion_matrix(y_test,y_pred_binary)\n",
    "plt.figure(figsize=(8,8))\n",
    "sns.heatmap(confusion,annot=True)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "\n",
    "print(classification_report(y_test,y_pred_binary))\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate balanced log loss\n",
    "bal_logloss = balanced_log_loss(y_test, y_pred_binary)\n",
    "print(\"balanced_log_loss is: \",bal_logloss)\n",
    "\n",
    "# Reset the warning filters to default if needed\n",
    "warnings.filterwarnings(\"default\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c8aa6c",
   "metadata": {
    "papermill": {
     "duration": 0.007935,
     "end_time": "2023-08-04T11:36:31.309349",
     "exception": false,
     "start_time": "2023-08-04T11:36:31.301414",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMClassifier.html\n",
    "\n",
    "https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html\n",
    "\n",
    "https://en.m.wikipedia.org/wiki/Cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65e8bd52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-04T11:36:31.326866Z",
     "iopub.status.busy": "2023-08-04T11:36:31.326457Z",
     "iopub.status.idle": "2023-08-04T11:36:31.370043Z",
     "shell.execute_reply": "2023-08-04T11:36:31.368858Z"
    },
    "papermill": {
     "duration": 0.055308,
     "end_time": "2023-08-04T11:36:31.372622",
     "exception": false,
     "start_time": "2023-08-04T11:36:31.317314",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.77413569, 0.22586431486160666], [0.77413569, 0.22586431486160666], [0.77413569, 0.22586431486160666], [0.77413569, 0.22586431486160666], [0.77413569, 0.22586431486160666]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20/1917825917.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_ds_pd['EJ'] = test_ds_pd['EJ'].map({'A':0, 'B':1})\n",
      "/tmp/ipykernel_20/1917825917.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_ds_pd.fillna(method='ffill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test_df = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/test.csv')\n",
    "\n",
    "test_ds_pd = test_df\n",
    "test_df_columns = test_ds_pd.columns.tolist()\n",
    "FEATURE_COLUMNS = [i for i in test_df.columns if i not in [\"Id\"]]\n",
    "TEST_FEATURE_COLUMNS = [i for i in FEATURE_COLUMNS \\\n",
    "                        if i in test_df_columns and i != \"Class\"]\n",
    "test_ds_pd = test_ds_pd[TEST_FEATURE_COLUMNS]\n",
    "\n",
    "test_ds_pd['EJ'] = test_ds_pd['EJ'].map({'A':0, 'B':1})\n",
    "# use forward fill to replace NaN with the previous valid value in each column.\n",
    "test_ds_pd.fillna(method='ffill', inplace=True)\n",
    "test_ds_pd = test_ds_pd.astype({'EJ':'float64'})\n",
    "# Normalizing to the range of 0 to 1\n",
    "min_val = test_ds_pd.min()\n",
    "max_val = test_ds_pd.max()\n",
    "df_norm = (test_ds_pd - min_val) / (max_val - min_val)\n",
    "\n",
    "predictions = model_lgb.predict(df_norm)\n",
    "n_predictions= [[round(abs(i-1), 8), i] for i in predictions.ravel()]\n",
    "print(n_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82824dbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-04T11:36:31.391252Z",
     "iopub.status.busy": "2023-08-04T11:36:31.390841Z",
     "iopub.status.idle": "2023-08-04T11:36:31.412203Z",
     "shell.execute_reply": "2023-08-04T11:36:31.411106Z"
    },
    "papermill": {
     "duration": 0.033422,
     "end_time": "2023-08-04T11:36:31.414545",
     "exception": false,
     "start_time": "2023-08-04T11:36:31.381123",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>class_0</th>\n",
       "      <th>class_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00eed32682bb</td>\n",
       "      <td>0.774136</td>\n",
       "      <td>0.225864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>010ebe33f668</td>\n",
       "      <td>0.774136</td>\n",
       "      <td>0.225864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02fa521e1838</td>\n",
       "      <td>0.774136</td>\n",
       "      <td>0.225864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>040e15f562a2</td>\n",
       "      <td>0.774136</td>\n",
       "      <td>0.225864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>046e85c7cc7f</td>\n",
       "      <td>0.774136</td>\n",
       "      <td>0.225864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id   class_0   class_1\n",
       "0  00eed32682bb  0.774136  0.225864\n",
       "1  010ebe33f668  0.774136  0.225864\n",
       "2  02fa521e1838  0.774136  0.225864\n",
       "3  040e15f562a2  0.774136  0.225864\n",
       "4  046e85c7cc7f  0.774136  0.225864"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission = pd.read_csv(\"/kaggle/input/icr-identify-age-related-conditions/sample_submission.csv\")\n",
    "sample_submission[['class_0', 'class_1']] = n_predictions\n",
    "sample_submission.to_csv('/kaggle/working/submission.csv', index=False)\n",
    "sample_submission.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 15.643789,
   "end_time": "2023-08-04T11:36:32.546698",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-08-04T11:36:16.902909",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
